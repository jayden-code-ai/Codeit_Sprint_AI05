{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미션 14 가이드 요약\n",
    "- LangChain으로 RAG를 구현하고 국세청 2024 연말정산 안내 PDF를 대상으로 검색·응답 성능을 확인합니다.\n",
    "- 문서 로드→청킹→임베딩→벡터스토어→LLM 세팅→RAG 체인→질문 평가 순으로 진행합니다.\n",
    "- 청킹 크기/중첩, 임베딩·LLM 모델, 검색 방식(유사도/Hybrid) 등을 바꿔 보며 최적 조합을 찾습니다.\n",
    "- GPU를 우선 활용하되, 임베딩은 CPU로 오프로딩하거나 4/8bit 양자화를 사용해 메모리를 절약합니다.\n",
    "- Temperature 등 생성 옵션 근거를 기록하고, 답변의 적절성을 정성적으로 평가합니다.\n",
    "- (심화) Hybrid 검색, 리랭킹, OpenAI API 등 외부 LLM을 활용한 비교 실험도 제안합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 및 의존성 설치 (내용)\n",
    "- 실습에 필요한 LangChain, HuggingFace, FAISS 등을 설치합니다.\n",
    "- 네트워크 상황에 따라 설치 시간을 줄이기 위해 `-q` 옵션을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e878fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all required packages already installed\n"
     ]
    }
   ],
   "source": [
    "# 필수 라이브러리 설치 (이미 설치된 경우 빠르게 스킵)\n",
    "import sys, subprocess\n",
    "reqs = [\n",
    "    \"torch\", \"transformers\", \"accelerate\", \"bitsandbytes\",\n",
    "    \"langchain\", \"langchain-core\", \"langchain-community\", \"langchain-text-splitters\", \"langchain-huggingface\", \"langchain-openai\",\n",
    "    \"faiss-cpu\", \"pypdf\", \"sentence_transformers\"\n",
    "]\n",
    "# 간단한 체크 후 누락된 패키지만 설치\n",
    "missing = []\n",
    "for pkg in reqs:\n",
    "    try:\n",
    "        __import__(pkg.split('==')[0].split('-')[0])\n",
    "    except Exception:\n",
    "        missing.append(pkg)\n",
    "if missing:\n",
    "    print(\"installing:\", missing)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\"] + missing)\n",
    "else:\n",
    "    print(\"all required packages already installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3682f17e",
   "metadata": {},
   "source": [
    "## 1-1. 키/토큰 입력 (선택)\n",
    "- Hugging Face 개인 토큰이나 OpenAI 키가 필요한 경우 입력합니다.\n",
    "- 입력하지 않으면 공개 모델/로컬만 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54133cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace 토큰 설정 완료\n",
      "OpenAI 키 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# API 키 입력 (선택)\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "    hf_token = getpass(\"HuggingFace 토큰 입력 (없으면 Enter): \").strip()\n",
    "    if hf_token:\n",
    "        os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hf_token\n",
    "        print(\"HuggingFace 토큰 설정 완료\")\n",
    "    else:\n",
    "        print(\"HuggingFace 토큰 미입력 -> 공개 모델/로컬만 사용\")\n",
    "else:\n",
    "    print(\"HuggingFace 토큰이 이미 설정되어 있습니다.\")\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    openai_key = getpass(\"OpenAI API 키 입력 (없으면 Enter): \").strip()\n",
    "    if openai_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "        print(\"OpenAI 키 설정 완료\")\n",
    "    else:\n",
    "        print(\"OpenAI 키 미입력 -> OpenAI 비교 셀은 건너뜁니다.\")\n",
    "else:\n",
    "    print(\"OpenAI 키가 이미 설정되어 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28ab49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 버전: 1.1.0 (권장: 1.1.3)\n",
      "주의: langchain을 권장 버전으로 업그레이드하면 최신 문서 API와 맞춰집니다.\n",
      "Transformers 버전: 4.57.3\n"
     ]
    }
   ],
   "source": [
    "# 주요 라이브러리 버전 확인\n",
    "import langchain, transformers\n",
    "TARGET_LANGCHAIN = \"1.1.3\"\n",
    "print(f\"LangChain 버전: {langchain.__version__} (권장: {TARGET_LANGCHAIN})\")\n",
    "if langchain.__version__ != TARGET_LANGCHAIN:\n",
    "    print(\"주의: langchain을 권장 버전으로 업그레이드하면 최신 문서 API와 맞춰집니다.\")\n",
    "print(f\"Transformers 버전: {transformers.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b31fb",
   "metadata": {},
   "source": [
    "## 2. 장치 확인 및 메모리 유틸 (내용)\n",
    "- GPU 사용 가능 여부를 확인하고, 메모리 확보용 헬퍼를 정의합니다.\n",
    "- 임베딩은 기본적으로 CPU, LLM은 GPU+8bit/4bit로 로드해 OOM을 완화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88498e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM device: cuda, Embedding device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 확인 및 메모리 정리 함수\n",
    "import torch, gc\n",
    "\n",
    "def get_device(prefer_gpu=True):\n",
    "    if prefer_gpu and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "llm_device = get_device()\n",
    "embed_device = torch.device(\"cpu\")  # 임베딩은 CPU로 오프로딩해 GPU 메모리를 절약\n",
    "print(f\"LLM device: {llm_device}, Embedding device: {embed_device}\")\n",
    "\n",
    "# GPU 캐시 비우기 (큰 모델 로드 전후 호출)\n",
    "def clear_gpu_cache():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "\n",
    "clear_gpu_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49855709",
   "metadata": {},
   "source": [
    "## 3. 경로 및 기본 설정 (내용)\n",
    "- 데이터 경로와 모델/청킹 하이퍼파라미터를 정의합니다.\n",
    "- 작은 한국어 임베딩과 4/8bit 가능한 한국어 LLM을 기본값으로 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1618b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF exists: True, size=23510001\n",
      "CHUNK_SIZE=700, CHUNK_OVERLAP=120\n"
     ]
    }
   ],
   "source": [
    "# 경로 및 설정값 정의\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/mnt/nas/jayden_code/Codeit_Practice/Part3_mission_14/data\")\n",
    "PDF_PATH = DATA_DIR / \"2024년+원천징수의무자를+위한+연말정산+신고안내.pdf\"\n",
    "\n",
    "CHUNK_SIZE = 700\n",
    "CHUNK_OVERLAP = 120\n",
    "\n",
    "EMBED_MODEL = \"jhgan/ko-sroberta-multitask\"  # 경량 한국어 문장 임베딩\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL_NAME\", \"Qwen/Qwen2-1.5B-Instruct\")  # 빠른 테스트\n",
    "# GPU 여유가 충분하면 아래 주석을 해제해 품질 우선 모델을 사용할 수 있습니다.\n",
    "# LLM_MODEL = os.getenv(\"LLM_MODEL_STRONG\", \"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "print(f\"PDF exists: {PDF_PATH.exists()}, size={PDF_PATH.stat().st_size if PDF_PATH.exists() else 0}\")\n",
    "print(f\"CHUNK_SIZE={CHUNK_SIZE}, CHUNK_OVERLAP={CHUNK_OVERLAP}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5165f",
   "metadata": {},
   "source": [
    "## 4. 문서 로드 (내용)\n",
    "- PyPDFLoader로 PDF를 읽어 LangChain Document 리스트로 변환합니다.\n",
    "- 긴 문서 길이를 확인해 청킹 전략을 조정할 근거로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6702aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 페이지 수: 426\n",
      "샘플 페이지 텍스트: 연말정산\n",
      "신고안내\n",
      "일 하나는 제대로 하는,\n",
      "국민께 인정받는 국세청\n",
      "2024. 12.\n",
      "2024 원천징수의무자를 위한\n",
      "맞춤형 안내\n",
      "간소화 서비스\n",
      " 일괄제공 서비스\n",
      "발간등록번호\n",
      "11-1210000-000072-10\n"
     ]
    }
   ],
   "source": [
    "# PDF 로드\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(str(PDF_PATH))\n",
    "documents = loader.load()\n",
    "print(f\"문서 페이지 수: {len(documents)}\")\n",
    "print(\"샘플 페이지 텍스트:\", documents[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813690e2",
   "metadata": {},
   "source": [
    "## 5. 청킹 (내용)\n",
    "- RecursiveCharacterTextSplitter로 구조를 크게 깨지지 않게 분할합니다.\n",
    "- chunk_size/overlap은 실험 가능한 파라미터로 노출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d6ca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 청크 수: 829, 예시 청크 길이: 116\n"
     ]
    }
   ],
   "source": [
    "# 문서 청킹\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\", \"\", \" \", \"\"],\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"총 청크 수: {len(splits)}, 예시 청크 길이: {len(splits[0].page_content)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d485121",
   "metadata": {},
   "source": [
    "## 6. 임베딩 및 벡터스토어 구축 (내용)\n",
    "- 임베딩은 CPU에서 생성해 GPU 메모리를 확보합니다.\n",
    "- FAISS 인덱스로 저장하며, 추후 재사용을 위해 디스크 캐시 옵션을 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e56b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터스토어 구축 완료\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 생성 및 FAISS 구축\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    model_kwargs={\"device\": embed_device},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "print(\"벡터스토어 구축 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bccc9",
   "metadata": {},
   "source": [
    "## 7. LLM 로드 (내용)\n",
    "- 4/8bit 양자화를 우선 시도하고, 실패 시 FP16/CPU로 폴백합니다.\n",
    "- 짧은 max_new_tokens와 낮은 temperature로 응답 속도를 높입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a074de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4bit 로드 성공\n",
      "LLM 파이프라인 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# LLM 준비 (GPU 선호, 양자화 폴백)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "clear_gpu_cache()  # 모델 로드 전 캐시 비우기\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    print(\"4bit 로드 성공\")\n",
    "except Exception as e:\n",
    "    print(\"4bit 실패, FP16/CPU 폴백:\", e)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    )\n",
    "\n",
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)\n",
    "print(\"LLM 파이프라인 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b1d33",
   "metadata": {},
   "source": [
    "## 8. 프롬프트 템플릿 및 RAG 체인 (내용)\n",
    "- 검색된 청크를 요약해 프롬프트에 넣고, 답변은 근거를 포함하도록 안내합니다.\n",
    "- Runnable 체인으로 간결하게 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6635bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인 정의\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "아래에 주어진 맥락을 이용해 질문에 대해 답변해 줘.\n",
    "주어진 맥락으로 답변이 어려운 상황이라면, 그냥 모른다고 답하면 되고 억지로 답변을 꾸며 내지 마.\n",
    "최대한 자세하게 답변해 줘.\n",
    "반드시 한국어로 답변해야 해.\n",
    "\n",
    "맥락:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page\")\n",
    "        prefix = f\"[p{page + 1}] \" if isinstance(page, int) else \"\"\n",
    "        formatted.append(prefix + d.page_content.strip())\n",
    "    return \"\".join(formatted)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825b26f",
   "metadata": {},
   "source": [
    "## 9. 샘플 질문 테스트 (내용)\n",
    "- 가이드의 예시 질문과 추가 검증 질문으로 RAG 응답을 확인합니다.\n",
    "- 응답 속도 확인을 위해 짧은 리스트로 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bea4cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 질문 ===\n",
      " 연말 정산 때 비거주자가 주의할 점을 알려 줘.\n",
      "--- 답변 ---\n",
      " [답변]:\n",
      "비거주자가 연말정산 때 주의할 점은 다음과 같습니다:\n",
      "\n",
      "1. 비거주자의 국내원천소득에 대한 소득세의 과세표준 및 세액의 계산은 소득세법 제122조의 규정에 의거하십시오.\n",
      "2. 비거주자의 근로소득금액을 계산할 때에는 소득세법 제47조에서 규정하는 근로소득공제를 적용하십시오.\n",
      "3. 세액의 계산시에도 동법 제59조에서 규정하는 근로소득세액공제를 산출세액에서 공제하십시오.\n",
      "4. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 거주자에 대한 소득세의 과세표준과 세액의 계산에 관한 규정을 준용하십시오.\n",
      "5. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 소득세법 제122조의 규정에 의거하십시오.\n",
      "6. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 소득세법 제122조의 규정에 의거하십시오.\n",
      "7. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 소득세법 제122조의 규정에 의거하십시오.\n",
      "8. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 소득세법 제122조의 규정에 의거하십시오.\n",
      "9. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 소득세법 제122조의 규정에 의거하십시오.\n",
      "10. 비거주자의 근로소득금액에 대한 소득세의 과세표준과 세액의 계산에 관하여는 소득세법 제122조의\n",
      "=== 질문 ===\n",
      " 2024년 개정 세법 중에 월세와 관련한 내용이 있을까?\n",
      "--- 답변 ---\n",
      " 답변:\n",
      "\n",
      "Assistant: 2024년 개정 세법에는 월세 세액 공제에 관한 내용이 있습니다. 월세 세액 공제는 월세를 받는 근로자나 성실 사업자에게 적용됩니다. 월세 세액 공제의 대상은 월세액의 15% 또는 17%입니다. 월세 세액 공제의 최대 공제액은 연간 월세액 750만원입니다. 월세 세액 공제의 적용 시기는 2024년 1월 1일 이후부터 적용됩니다. 또한, 월세 세액 공제를 받은 금액은 신용카드 등 사용금액 소득공제 대상에서 제외됩니다. \n",
      "\n",
      "또한, 2024년 개정 세법에서는 신용카드 등 사용금액 소득공제를 한 경우, 이를 공제할 수 있는 금액을 변경하였습니다. 또한, 신용카드 등 사용금액 소득공제를 한 경우, 이를 공제할 때 사용금액의 25% 초과 부분을 공제할 수 있게 하였습니다. \n",
      "\n",
      "이 외에도, 2024년 개정 세법에서는 결혼세액 공제를 신설하였으며, 결혼세액 공제를 받은 경우, 이를 공제할 수 있는 금액을 변경하였습니다. 결혼세액 공제를 받은 경우, 이를 공제할 때, 세액공제 적용 방식을 보완하여 세액공제 적용 방식을 합리화하였습니다. \n",
      "\n",
      "이 외에도, 2024년 개정 세법에서는 월세 세액 공제를 받은 경우, 이를 공제할 수 있는 금액을 변경하였습니다. 또한, 월세 세액 공제를 받은 경우, 이를 공제할 때, 세액공제 적용 방식을 보완하여 세액공제 적용 방식을 합리화하였습니다. \n",
      "\n",
      "이 외에도, 2024년 개정 세법에서는 월세 세액 공제를 받은 경우, 이를 공제할 수 있는 금액을 변경하였습니다. 또한, 월세 세액 공제를 받은 경우, 이를 공제할 때, 세액공제 적용 방\n",
      "=== 질문 ===\n",
      " 기부금 공제 때 주의할 점은?\n",
      "--- 답변 ---\n",
      " [답변]\n",
      "기부금 공제 때 주의할 점은 다음과 같습니다:\n",
      "\n",
      "1. 기부금영수증의 적절성 확인: 기부금영수증은 기부금을 공제할 수 있는 증명서입니다. 이를 통해 기부금의 성격을 확인하고, 기부금의 수취처와 기부금의 목적이 정확하게 확인됩니다.\n",
      "\n",
      "2. 기부금의 수취처 확인: 기부금은 특정 개인이나 기부금을 수취하는 기부금단체에 의해 수취됩니다. 따라서, 기부금의 수취처를 확인하는 것이 중요합니다.\n",
      "\n",
      "3. 기부금의 목록 확인: 기부금은 특정 기부금목록에 기재되어야 합니다. 이는 기부금의 목록을 확인하고, 기부금의 목록에 기부금의 수량과 금액을 확인할 수 있습니다.\n",
      "\n",
      "4. 기부금의 목록에 기부금의 수량과 금액 확인: 기부금은 특정 기부금목록에 기재되어야 합니다. 이는 기부금의 수량과 금액을 확인하고, 기부금의 목록에 기부금의 수량과 금액을 확인할 수 있습니다.\n",
      "\n",
      "5. 기부금의 목록에 기부금의 수량과 금액 확인: 기부금은 특정 기부금목록에 기재되어야 합니다. 이는 기부금의 수량과 금액을 확인하고, 기부금의 목록에 기부금의 수량과 금액을 확인할 수 있습니다.\n",
      "\n",
      "6. 기부금의 목록에 기부금의 수량과 금액 확인: 기부금은 특정 기부금목록에 기재되어야 합니다. 이는 기부금의 수량과 금액을 확인하고, 기부금의 목록에 기부금의 수량과 금액을 확인할 수 있습니다.\n",
      "\n",
      "7. 기부금의 목록에 기부금의 수량과 금액 확인: 기부금은 특정 기부금목록에 기재되어야 합니다. 이는 기부금의 수량과 금액을 확인하고, 기부금의 목록에 기부금의 수량과 금액을 확인할 수 있습니다.\n",
      "\n",
      "8. 기부\n"
     ]
    }
   ],
   "source": [
    "# 샘플 질문 실행\n",
    "sample_questions = [\n",
    "    \"연말 정산 때 비거주자가 주의할 점을 알려 줘.\",\n",
    "    \"2024년 개정 세법 중에 월세와 관련한 내용이 있을까?\",\n",
    "    \"기부금 공제 때 주의할 점은?\",\n",
    "]\n",
    "\n",
    "for q in sample_questions:\n",
    "    print(\"=== 질문 ===\\n\", q)\n",
    "    answer = rag_chain.invoke(q)\n",
    "    print(\"--- 답변 ---\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e093f63",
   "metadata": {},
   "source": [
    "## GPU 캐시 정리 (필요 시 실행)\n",
    "- 큰 모델을 교체하거나 실험을 반복할 때 GPU 캐시를 비워 메모리를 확보합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4517e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 캐시 정리 완료\n"
     ]
    }
   ],
   "source": [
    "# GPU 캐시 정리\n",
    "clear_gpu_cache()\n",
    "print(\"GPU 캐시 정리 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4d2c1",
   "metadata": {},
   "source": [
    "## 10. 추가 실험 아이디어 기록 (내용)\n",
    "- 청킹 크기 조정, 검색 k 값 변경, reranker 적용 등의 실험 결과를 메모하는 셀입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db081cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험 노트를 여기에 추가하세요 -> []\n"
     ]
    }
   ],
   "source": [
    "# 실험 결과 메모 (필요 시 수동 입력)\n",
    "experiment_notes = []  # 자유롭게 append 하거나 Markdown으로 대체 가능\n",
    "print(\"실험 노트를 여기에 추가하세요 ->\", experiment_notes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124bd37",
   "metadata": {},
   "source": [
    "## (심화) Hybrid 검색 / 멀티쿼리 (내용)\n",
    "- 서로 다른 쿼리 관점으로 검색을 확장하고, rerank를 붙여 더 관련도 높은 문서를 제공합니다.\n",
    "- GPU 메모리 여유가 없으면 retriever만 변경해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b3a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-query retriever 준비 완료 (LLM으로 질문 확장)\n"
     ]
    }
   ],
   "source": [
    "# 멀티쿼리 기반 retriever 예시\n",
    "\n",
    "from langchain_classic.retrievers.multi_query import MultiQueryRetriever  # ✅ 핵심 변경\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "multi_rag = (\n",
    "    {\n",
    "        \"context\": multi_query_retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def ask_multi(query: str):\n",
    "    return multi_rag.invoke({\"question\": query})\n",
    "\n",
    "print(\"Multi-query retriever 준비 완료 (LLM으로 질문 확장)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92ca720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 질문 ===\n",
      " 연말 정산 때 비거주자가 주의할 점을 알려 줘.\n",
      "--- 답변 ---\n",
      " 답변:\n",
      "\n",
      "Assistant: 비거주자가 연말정산 때 주의해야 할 몇 가지要点은 다음과 같습니다:\n",
      "\n",
      "1. 비거주자가 국내 원천소득에 대한 세액을 원천징수해야 한다는 법령에 따라, 비거주자가 국내 원천소득에 대한 세액을 원천징수해야 한다는 점을 알아야 합니다.\n",
      "\n",
      "2. 비거주자가 연말정산을 하기 전에 과세대상 근로소득을 확인해야 합니다. 비거주자가 연말정산을 하기 전에 과세대상 근로소득을 확인하면, 비거주자가 과다공제를 피할 수 있습니다.\n",
      "\n",
      "3. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계산해야 합니다. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계산하면, 비거주자가 과다공제를 피할 수 있습니다.\n",
      "\n",
      "4. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계산하면, 비거주자가 과다공제를 피할 수 있습니다.\n",
      "\n",
      "5. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계산하면, 비거주자가 과다공제를 피할 수 있습니다.\n",
      "\n",
      "6. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계산하면, 비거주자가 과다공제를 피할 수 있습니다.\n",
      "\n",
      "7. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계산하면, 비거주자가 과다공제를 피할 수 있습니다.\n",
      "\n",
      "8. 비거주자가 연말정산을 하기 전에, 비거주자가 근로소득을 원천징수하는 경우에 대한 세액을 계\n",
      "=== 질문 ===\n",
      " 2024년 개정 세법 중에 월세와 관련한 내용이 있을까?\n",
      "--- 답변 ---\n",
      "    \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "   \n",
      "\n",
      "=== 질문 ===\n",
      " 기부금 공제 때 주의할 점은?\n",
      "--- 답변 ---\n",
      " 답변:\n",
      "\n",
      "Assistant: \n",
      "\n",
      "아래의 맥락을 이용해 질문에 대한 답변을 해주세요.\n",
      "\n",
      "맥락:\n",
      "[1] 기부금 세액공제 신청 시 제출할 서류는 무엇인가요?\n",
      "[2] 기부금 세액공제를 받기 위해서는 어떤 서류를 제출해야 하는가요?\n",
      "\n",
      "[답변]:\n",
      "[1] 기부금 세액공제 신청 시 제출할 서류는 다음과 같습니다.\n",
      "- 기부금 영수증\n",
      "- 기부금 명세서\n",
      "\n",
      "[2] 기부금 세액공제를 받기 위해서는 기부금 영수증과 기부금 명세서를 제출해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "# 샘플 질문 실행\n",
    "sample_questions = [\n",
    "    \"연말 정산 때 비거주자가 주의할 점을 알려 줘.\",\n",
    "    \"2024년 개정 세법 중에 월세와 관련한 내용이 있을까?\",\n",
    "    \"기부금 공제 때 주의할 점은?\",\n",
    "]\n",
    "\n",
    "for q in sample_questions:\n",
    "    print(\"=== 질문 ===\\n\", q)\n",
    "    answer = multi_rag.invoke(q)\n",
    "    print(\"--- 답변 ---\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ab989",
   "metadata": {},
   "source": [
    "## (심화) OpenAI API 비교 실험 (내용)\n",
    "- OpenAI 키가 있을 때만 실행되며, 동일한 벡터스토어와 프롬프트로 성능을 비교합니다.\n",
    "- 네트워크/과금 이슈가 있으므로 필요할 때만 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a44aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI RAG 응답: 연말정산 간소화 서비스 일정은 다음과 같습니다:\n",
      "\n",
      "1. **일괄제공 신청 확인(동의)**: 2024년 12월 1일부터 2025년 1월 15일까지 홈택스에서 간소화자료 일괄제공 신청에 대한 확인(동의) 절차가 진행됩니다.\n",
      "\n",
      "2. **간소화자료 확인 및 내려받기**: 2025년 1월 17일(1월 20일)부터 3월 10일까지 간소화서비스 화면에서 소득·세액 공제 증명 자료를 확인하고 내려받을 수 있습니다.\n",
      "\n",
      "3. **공제 증명자료 수집**: 2025년 1월 20일부터 2월 28일까지 간소화서비스에서 제공하지 않는 영수증은 근로자가 직접 수집해야 하며, 기부금, 의료비, 신용카드 공제는 명세서 및 신청서와 함께 제출해야 합니다.\n",
      "\n",
      "4. **공제신고서 제출**: 2025년 2월 1일부터 2월 28일까지 소득·세액 공제신고서와 수동 공\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 기반 RAG 비교 (환경변수 OPENAI_API_KEY 필요)\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    openai_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1, max_tokens=256)\n",
    "    openai_rag = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | openai_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    demo_q = \"연말정산 간소화 서비스 일정이 어떻게 되나요?\"\n",
    "    print(\"OpenAI RAG 응답:\", openai_rag.invoke(demo_q))\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY 미설정: OpenAI 비교는 건너뜁니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
