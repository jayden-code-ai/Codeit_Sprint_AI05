{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d5e4df",
   "metadata": {},
   "source": [
    "\n",
    "# Seq2Seq 실습 1: 영어-한국어 번역\n",
    "### 1. 환경 설정 및 라이브러리 설치\n",
    "\n",
    "* `torch`: 딥러닝 프레임워크\n",
    "* `torchtext`: 텍스트 처리를 위한 라이브러리\n",
    "* `spacy`: 영어 토큰화\n",
    "* `konlpy`: 한국어 토큰화 (Okt 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9774b082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.3.0\n",
      "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.18.0\n",
      "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio==2.3.0\n",
      "  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting torchtext==0.18.0\n",
      "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: filelock in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Collecting triton==2.3.0 (from torch==2.3.0)\n",
      "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torchvision==0.18.0) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torchvision==0.18.0) (11.3.0)\n",
      "Requirement already satisfied: tqdm in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torchtext==0.18.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from torchtext==0.18.0) (2.28.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from jinja2->torch==2.3.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests->torchtext==0.18.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests->torchtext==0.18.0) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests->torchtext==0.18.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests->torchtext==0.18.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, torch, torchvision, torchtext, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 2.3.1\n",
      "\u001b[2K    Uninstalling triton-2.3.1:\n",
      "\u001b[2K      Successfully uninstalled triton-2.3.1\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/5\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: torch 2.3.1+cu121[32m0/5\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling torch-2.3.1+cu121:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.3.1+cu121━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.18.1+cu121━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.18.1+cu121:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.18.1+cu121━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [torchaudio]5\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch-2.3.0 torchaudio-2.3.0 torchtext-0.18.0 torchvision-0.18.0 triton-2.3.0\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting konlpy\n",
      "  Using cached konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Using cached weasel-0.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (2.3.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (60.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Using cached cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Using cached smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading wrapt-2.0.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Downloading lxml-6.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Downloading spacy-3.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.3/32.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)\n",
      "Downloading preshed-3.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (842 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m842.9/842.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.2-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Using cached smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Using cached konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "Downloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (496 kB)\n",
      "Downloading lxml-6.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-2.0.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (114 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, typer-slim, spacy-loggers, spacy-legacy, murmurhash, lxml, JPype1, cloudpathlib, catalogue, blis, srsly, smart-open, preshed, konlpy, confection, weasel, thinc, spacy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [spacy]m19/20\u001b[0m [spacy]open]\n",
      "\u001b[1A\u001b[2KSuccessfully installed JPype1-1.6.0 blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.11 konlpy-0.6.0 lxml-6.0.2 murmurhash-1.0.13 preshed-3.0.10 smart-open-7.5.0 spacy-3.8.8 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.8 typer-slim-0.20.0 wasabi-1.1.3 weasel-0.4.2 wrapt-2.0.1\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "E: 잠금 파일 /var/lib/dpkg/lock-frontend 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "# Colab 셀 1: 라이브러리 설치\n",
    "# torch 및 torchtext의 호환되는 버전을 명시하여 설치\n",
    "# !pip uninstall -y torch torchtext torchvision torchaudio\n",
    "!pip install --upgrade torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 torchtext==0.18.0\n",
    "!pip install spacy konlpy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# konlpy 사용을 위한 자바 설치\n",
    "!apt-get install openjdk-8-jdk -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b065b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "0.18.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4ca152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping jpype as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: jpype1 1.6.0\n",
      "Uninstalling jpype1-1.6.0:\n",
      "  Successfully uninstalled jpype1-1.6.0\n",
      "패키지 목록을 읽는 중입니다... 완료0%\n",
      "E: 잠금 파일 /var/lib/apt/lists/lock 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: /var/lib/apt/lists/ 디렉터리를 잠글 수 없습니다\n",
      "W: /var/cache/apt/pkgcache.bin 파일을 삭제하는데 문제가 있습니다 - RemoveCaches (13: 허가 거부)\n",
      "W: /var/cache/apt/srcpkgcache.bin 파일을 삭제하는데 문제가 있습니다 - RemoveCaches (13: 허가 거부)\n",
      "E: 잠금 파일 /var/lib/dpkg/lock-frontend 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Collecting JPype1==1.4.1\n",
      "  Downloading JPype1-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: packaging in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from JPype1==1.4.1) (25.0)\n",
      "Downloading JPype1-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (464 kB)\n",
      "Installing collected packages: JPype1\n",
      "Successfully installed JPype1-1.4.1\n",
      "Requirement already satisfied: konlpy in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from konlpy) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.6 in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from konlpy) (2.3.3)\n",
      "Requirement already satisfied: packaging in /home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages (from JPype1>=0.7.0->konlpy) (25.0)\n"
     ]
    }
   ],
   "source": [
    "# 1) JPype 관련 패키지 싹 제거\n",
    "!pip uninstall -y jpype JPype1 jpype1\n",
    "\n",
    "# 2) 자바 설치 (Colab용, JDK 17)\n",
    "!apt-get -y update\n",
    "!apt-get -y install openjdk-17-jdk-headless\n",
    "\n",
    "# 3) JPype1, konlpy 깔끔하게 재설치\n",
    "!pip install JPype1==1.4.1\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b45a392",
   "metadata": {},
   "source": [
    "### 2. 데이터 다운로드 및 전처리\n",
    "\n",
    "[Tatoeba 프로젝트](http://www.manythings.org/anki/)의 소규모 영-한 병렬 코퍼스를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e3543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-10 13:10:50--  http://www.manythings.org/anki/kor-eng.zip\n",
      "www.manythings.org (www.manythings.org) 해석 중... 173.254.30.110\n",
      "다음으로 연결 중: www.manythings.org (www.manythings.org)|173.254.30.110|:80... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 253046 (247K) [application/zip]\n",
      "저장 위치: ‘kor-eng.zip’\n",
      "\n",
      "kor-eng.zip         100%[===================>] 247.12K   401KB/s    / 0.6s     \n",
      "\n",
      "2025-11-10 13:10:51 (401 KB/s) - ‘kor-eng.zip’ 저장함 [253046/253046]\n",
      "\n",
      "Archive:  kor-eng.zip\n",
      "  inflating: _about.txt              \n",
      "  inflating: kor.txt                 \n"
     ]
    }
   ],
   "source": [
    "# Colab 셀 2: 데이터 다운로드 및 압축 해제\n",
    "!wget http://www.manythings.org/anki/kor-eng.zip\n",
    "!unzip kor-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60a56e",
   "metadata": {},
   "source": [
    "### 3. 기본 라이브러리 임포트 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256a05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/jayden86/miniconda3/envs/ai5_project1/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import spacy\n",
    "from konlpy.tag import Okt          # 한국어 형태소 분석기(예: \"사과를 먹었다\">>['사과', '를', '먹었', '다']\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "\n",
    "# 딥러닝이나 머신러닝에서는 모델 학습 과정에 무작위(random) 요소 많음: 가중치, 셔플, dropout ...\n",
    "# 매번 같은 결과를 재현위해서 시드 고정: “같은 코드 + 같은 데이터 + 같은 시드 → 같은 결과!”\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8b336",
   "metadata": {},
   "source": [
    "### 4. 토크나이저 정의\n",
    "\n",
    "영어는 `spaCy`, 한국어는 `Okt`를 사용해 토크나이저를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4d759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'my', 'name', 'is', 'Kim', '.']\n",
      "['안녕하세요', ',', '제', '이름', '은', '김', '입니다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 로드 및 정의\n",
    "import spacy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "okt = Okt()\n",
    "\n",
    "def tokenize_en(text):\n",
    "  \"\"\"\n",
    "  spaCy를 사용한 영어 토크나이저\n",
    "  \"\"\"\n",
    "  return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_ko(text):\n",
    "  \"\"\"\n",
    "  Okt를 사용한 한국어 토크나이저\n",
    "  \"\"\"\n",
    "  return okt.morphs(text)\n",
    "\n",
    "# 테스트\n",
    "print(tokenize_en(\"Hello, my name is Kim.\"))\n",
    "print(tokenize_ko(\"안녕하세요, 제 이름은 김입니다.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4c579",
   "metadata": {},
   "source": [
    "### 5. 데이터 로드 및 어휘장(Vocabulary) 구축\n",
    "\n",
    "다운로드한 `kor.txt` 파일(탭으로 구분)을 읽고, 영어와 한국어 어휘장을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a658dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English vocab...\n",
      "Building Korean vocab...\n",
      "English Vocab Size: 918\n",
      "Korean Vocab Size: 1014\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "# 데이터 로드 및 어휘장 구축\n",
    "DATA_PATH = 'kor.txt'\n",
    "MIN_FREQ = 5   #단어장에 포함될 최소 빈도\n",
    "\n",
    "# 특수 토큰 정의\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "\n",
    "# 영어/한국어 토큰 제너레이터\n",
    "def yield_en_tokens(data_path, tokenizer_en):\n",
    "  with io.open(data_path, encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "      parts = line.strip().split('\\t')\n",
    "      if len(parts) >= 2:\n",
    "        yield tokenizer_en(parts[0])\n",
    "\n",
    "def yield_ko_tokens(data_path, tokenizer_ko):\n",
    "  with io.open(data_path, encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "      parts = line.strip().split('\\t')\n",
    "      if len(parts) >= 2:\n",
    "        yield tokenizer_ko(parts[1])\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "print(\"Building English vocab...\")\n",
    "vocab_en = build_vocab_from_iterator(\n",
    "    yield_en_tokens(DATA_PATH, tokenize_en),\n",
    "    min_freq=MIN_FREQ,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "vocab_en.set_default_index(UNK_IDX) # <unk> 토큰의 인덱스를 기본값으로 설정\n",
    "\n",
    "print(\"Building Korean vocab...\")\n",
    "vocab_ko = build_vocab_from_iterator(\n",
    "    yield_ko_tokens(DATA_PATH, tokenize_ko),\n",
    "    min_freq=MIN_FREQ,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "vocab_ko.set_default_index(UNK_IDX)\n",
    "\n",
    "print(f\"English Vocab Size: {len(vocab_en)}\")\n",
    "print(f\"Korean Vocab Size: {len(vocab_ko)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52541d2",
   "metadata": {},
   "source": [
    "### 6. Dataset 및 DataLoader 정의\n",
    "\n",
    "PyTorch의 `Dataset`과 `DataLoader`를 사용하여 데이터를 배치 단위로 처리할 수 있도록 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ea9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 정의\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EngKorDataset(Dataset):\n",
    "  def __init__(self, data_path, vocab_en, vocab_ko, tokenizer_en, tokenizer_ko):\n",
    "    self.vocab_en = vocab_en\n",
    "    self.vocab_ko = vocab_ko\n",
    "    self.tokenizer_en = tokenizer_en\n",
    "    self.tokenizer_ko = tokenizer_ko\n",
    "    self.data = []\n",
    "\n",
    "    with io.open(data_path, encoding='utf-8') as f:\n",
    "      for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 2:\n",
    "          # [영어, 한국어] 쌍으로 저장\n",
    "          self.data.append((parts[0], parts[1]))\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      eng_text, kor_text = self.data[idx]\n",
    "      return eng_text, kor_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e79a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Source batch shape: torch.Size([14, 128])\n",
      "Target batch shape: torch.Size([17, 128]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Collate 함수 및 DataLoader 생성\n",
    "def collate_fn(batch):\n",
    "  \"\"\"\n",
    "    PyTorch의 DataLoader는 여러 샘플을 묶어 **하나의 배치(batch)**로 만듭니다.\n",
    "    하지만 NLP에서는 문장의 길이가 제각각이라 단순히 묶기 어렵습니다.\n",
    "    collate_fn은 각 문장을 토큰화 → 인덱스 변환 → 패딩(padding) 해서 동일한 길이로 만들어주는 함수\n",
    "  \"\"\"\n",
    "  src_batch, trg_batch = [], []\n",
    "  for src_sample, trg_sample in batch:\n",
    "      # 1. 토큰화\n",
    "      src_tokens = [tok for tok in tokenize_en(src_sample.lower())]\n",
    "      trg_tokens = [tok for tok in tokenize_ko(trg_sample)]\n",
    "\n",
    "      # 2. <sos> 및 <eos> 추가\n",
    "      src_with_eos = src_tokens + ['<eos>']\n",
    "      trg_with_sos_eos = ['<sos>'] + trg_tokens + ['<eos>']\n",
    "\n",
    "      # 3. 수치화 (Vocab 사용)\n",
    "      src_indices = [vocab_en[token] for token in src_with_eos]\n",
    "      trg_indices = [vocab_ko[token] for token in trg_with_sos_eos]\n",
    "\n",
    "      src_batch.append(torch.tensor(src_indices, dtype=torch.long))\n",
    "      trg_batch.append(torch.tensor(trg_indices, dtype=torch.long))\n",
    "\n",
    "  # 4. 패딩: RNN은 가변 길이 시퀀스를 받지만, 배치는 고정 길이여야 함\n",
    "  # pad_sequence는 (seq_len, batch_size) 형태의 텐서를 만듦\n",
    "  src_padded = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "  trg_padded = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
    "\n",
    "  return src_padded.to(device), trg_padded.to(device)\n",
    "\n",
    "\n",
    "# 데이터셋 분리 (학습 / 검증 / 테스트)\n",
    "full_dataset = EngKorDataset(DATA_PATH, vocab_en, vocab_ko, tokenize_en, tokenize_ko)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "# Test 셋은 편의상 Valid 셋과 동일하게 사용 (원래는 분리해야 함)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 데이터로더 테스트\n",
    "src_batch, trg_batch = next(iter(train_loader))\n",
    "print(f\"Source batch shape: {src_batch.shape}\") # (src_len, batch_size)\n",
    "print(f\"Target batch shape: {trg_batch.shape})\") # (trg_len, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbf67e",
   "metadata": {},
   "source": [
    "### 7. Seq2Seq 모델 정의\n",
    "\n",
    "#### 7.1. Encoder (인코더)\n",
    "\n",
    "인코더는 입력 문장(영어)을 받아 하나의 '컨텍스트 벡터'(Context Vector)로 압축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfe3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Encoder 정의\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # 1. 임베딩 층\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        # 2. RNN 층 (GRU 사용)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "\n",
    "        # 3. 드롭아웃\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "\n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1a394",
   "metadata": {},
   "source": [
    "#### 7.2. Decoder (디코더)\n",
    "\n",
    "디코더는 인코더의 컨텍스트 벡터와 이전 타임스텝의 예측 단어를 받아 다음 단어를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "866d2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 정의\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # 1. 임베딩 층\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        # 2. RNN 층 (GRU 사용)\n",
    "        # 인코더와 동일한 파라미터를 가져야 함\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "\n",
    "        # 3. Fully Connected (Linear) 층\n",
    "        # RNN의 hidden state를 받아 어휘장 크기의 벡터로 변환\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input: (batch_size) - 현재 time-step의 입력 단어 (t)\n",
    "        # hidden: (n_layers, batch_size, hid_dim) - 이전 time-step의 hidden state (t-1)\n",
    "\n",
    "        # 1. 입력 단어 임베딩\n",
    "        # (batch_size) -> (1, batch_size)로 변환 (GRU는 seq_len 차원이 필요)\n",
    "        input = input.unsqueeze(0)\n",
    "        # input: (1, batch_size)\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded: (1, batch_size, emb_dim)\n",
    "\n",
    "        # 2. RNN 통과\n",
    "        # 디코더는 매 스텝마다 컨텍스트 벡터(hidden)를 업데이트\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "\n",
    "        # output: (1, batch_size, hid_dim)\n",
    "        # hidden: (n_layers, batch_size, hid_dim)\n",
    "\n",
    "        # 3. 예측 (Linear 층)\n",
    "        # (1, batch_size, hid_dim) -> (batch_size, output_dim)\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction: (batch_size, output_dim) - 한국어 어휘장 크기의 로짓(logit)\n",
    "\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce00c9",
   "metadata": {},
   "source": [
    "#### 7.3. Seq2Seq (모델 결합)\n",
    "\n",
    "인코더와 디코더를 결합하고, 'Teacher Forcing'을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3d570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq 모델 정의\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        # 인코더와 디코더의 hidden dim이 일치해야 함\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have same number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88cd32",
   "metadata": {},
   "source": [
    "### 8. 모델 학습\n",
    "\n",
    "#### 8.1. 하이퍼파라미터 및 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e596d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6,532,086 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn # Add this import for CrossEntropyLoss\n",
    "import torch # Add this import for torch.cuda.is_available() and torch.manual_seed\n",
    "\n",
    "# 모델 파라미터 및 초기화\n",
    "INPUT_DIM = len(vocab_en)\n",
    "OUTPUT_DIM = len(vocab_ko)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "# 파라미터 수 확인\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "# 옵티마이저 (Adam)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 손실 함수 (CrossEntropyLoss)\n",
    "# <pad> 토큰(인덱스 1)은 무시하도록 ignore_index 설정\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88ba54",
   "metadata": {},
   "source": [
    "#### 8.2. 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e92054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train() # 학습 모드\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1. 모델 순전파\n",
    "        # teacher_forcing_ratio = 0.5 (50% 확률로 Teacher Forcing 사용)\n",
    "        output = model(src, trg, 0.5)\n",
    "\n",
    "        # output: (trg_len, batch_size, output_dim)\n",
    "        # trg: (trg_len, batch_size)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # 2. 손실 계산\n",
    "        # CrossEntropyLoss는 (N, C) 형태의 2D 입력과 (N) 형태의 1D 타겟을 기대함\n",
    "        # <sos> 토큰(인덱스 0)은 예측 대상이 아니므로 [1:] 부터 사용\n",
    "        output = output[1:].view(-1, output_dim) # ( (trg_len-1) * batch_size, output_dim )\n",
    "        trg = trg[1:].view(-1)                   # ( (trg_len-1) * batch_size )\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        # 3. 역전파 및 가중치 업데이트\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Gradient Clipping (폭주 방지)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a7c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval() # 평가 모드\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad(): # 그래디언트 계산 비활성화\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "\n",
    "            # 1. 모델 순전파 (평가 시에는 Teacher Forcing 사용 안 함)\n",
    "            output = model(src, trg, 0) # teacher_forcing_ratio = 0\n",
    "\n",
    "            # 2. 손실 계산 (마찬가지로 <sos> 토큰 제외)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb78e",
   "metadata": {},
   "source": [
    "#### 8.3. 실제 학습 실행 : 약 2분 시간 걸림\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6db025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 4s\n",
      "\tTrain Loss: 4.513 | Train PPL:  91.224\n",
      "\t Val. Loss: 4.302 |  Val. PPL:  73.832\n",
      "Epoch: 02 | Time: 0m 4s\n",
      "\tTrain Loss: 4.037 | Train PPL:  56.638\n",
      "\t Val. Loss: 4.182 |  Val. PPL:  65.513\n",
      "Epoch: 03 | Time: 0m 4s\n",
      "\tTrain Loss: 3.809 | Train PPL:  45.108\n",
      "\t Val. Loss: 4.013 |  Val. PPL:  55.337\n",
      "Epoch: 04 | Time: 0m 5s\n",
      "\tTrain Loss: 3.587 | Train PPL:  36.133\n",
      "\t Val. Loss: 3.884 |  Val. PPL:  48.604\n",
      "Epoch: 05 | Time: 0m 5s\n",
      "\tTrain Loss: 3.461 | Train PPL:  31.847\n",
      "\t Val. Loss: 3.832 |  Val. PPL:  46.176\n",
      "Epoch: 06 | Time: 0m 5s\n",
      "\tTrain Loss: 3.315 | Train PPL:  27.509\n",
      "\t Val. Loss: 3.758 |  Val. PPL:  42.847\n",
      "Epoch: 07 | Time: 0m 6s\n",
      "\tTrain Loss: 3.180 | Train PPL:  24.049\n",
      "\t Val. Loss: 3.757 |  Val. PPL:  42.811\n",
      "Epoch: 08 | Time: 0m 6s\n",
      "\tTrain Loss: 3.075 | Train PPL:  21.643\n",
      "\t Val. Loss: 3.711 |  Val. PPL:  40.906\n",
      "Epoch: 09 | Time: 0m 6s\n",
      "\tTrain Loss: 2.995 | Train PPL:  19.984\n",
      "\t Val. Loss: 3.674 |  Val. PPL:  39.419\n",
      "Epoch: 10 | Time: 0m 6s\n",
      "\tTrain Loss: 2.859 | Train PPL:  17.452\n",
      "\t Val. Loss: 3.706 |  Val. PPL:  40.671\n",
      "Epoch: 11 | Time: 0m 6s\n",
      "\tTrain Loss: 2.762 | Train PPL:  15.836\n",
      "\t Val. Loss: 3.621 |  Val. PPL:  37.366\n",
      "Epoch: 12 | Time: 0m 6s\n",
      "\tTrain Loss: 2.637 | Train PPL:  13.975\n",
      "\t Val. Loss: 3.665 |  Val. PPL:  39.059\n",
      "Epoch: 13 | Time: 0m 5s\n",
      "\tTrain Loss: 2.595 | Train PPL:  13.397\n",
      "\t Val. Loss: 3.637 |  Val. PPL:  37.976\n",
      "Epoch: 14 | Time: 0m 5s\n",
      "\tTrain Loss: 2.536 | Train PPL:  12.629\n",
      "\t Val. Loss: 3.608 |  Val. PPL:  36.910\n",
      "Epoch: 15 | Time: 0m 5s\n",
      "\tTrain Loss: 2.393 | Train PPL:  10.945\n",
      "\t Val. Loss: 3.584 |  Val. PPL:  36.023\n",
      "Epoch: 16 | Time: 0m 5s\n",
      "\tTrain Loss: 2.357 | Train PPL:  10.557\n",
      "\t Val. Loss: 3.579 |  Val. PPL:  35.837\n",
      "Epoch: 17 | Time: 0m 5s\n",
      "\tTrain Loss: 2.246 | Train PPL:   9.450\n",
      "\t Val. Loss: 3.598 |  Val. PPL:  36.539\n",
      "Epoch: 18 | Time: 0m 5s\n",
      "\tTrain Loss: 2.156 | Train PPL:   8.639\n",
      "\t Val. Loss: 3.602 |  Val. PPL:  36.665\n",
      "Epoch: 19 | Time: 0m 6s\n",
      "\tTrain Loss: 2.089 | Train PPL:   8.080\n",
      "\t Val. Loss: 3.626 |  Val. PPL:  37.559\n",
      "Epoch: 20 | Time: 0m 5s\n",
      "\tTrain Loss: 2.000 | Train PPL:   7.389\n",
      "\t Val. Loss: 3.677 |  Val. PPL:  39.518\n",
      "Epoch: 21 | Time: 0m 5s\n",
      "\tTrain Loss: 1.951 | Train PPL:   7.035\n",
      "\t Val. Loss: 3.630 |  Val. PPL:  37.722\n",
      "Epoch: 22 | Time: 0m 5s\n",
      "\tTrain Loss: 1.890 | Train PPL:   6.619\n",
      "\t Val. Loss: 3.639 |  Val. PPL:  38.036\n",
      "Epoch: 23 | Time: 0m 6s\n",
      "\tTrain Loss: 1.815 | Train PPL:   6.140\n",
      "\t Val. Loss: 3.625 |  Val. PPL:  37.519\n",
      "Epoch: 24 | Time: 0m 6s\n",
      "\tTrain Loss: 1.730 | Train PPL:   5.643\n",
      "\t Val. Loss: 3.686 |  Val. PPL:  39.869\n",
      "Epoch: 25 | Time: 0m 6s\n",
      "\tTrain Loss: 1.686 | Train PPL:   5.398\n",
      "\t Val. Loss: 3.695 |  Val. PPL:  40.234\n",
      "Epoch: 26 | Time: 0m 6s\n",
      "\tTrain Loss: 1.597 | Train PPL:   4.938\n",
      "\t Val. Loss: 3.752 |  Val. PPL:  42.617\n",
      "Epoch: 27 | Time: 0m 5s\n",
      "\tTrain Loss: 1.552 | Train PPL:   4.719\n",
      "\t Val. Loss: 3.772 |  Val. PPL:  43.455\n",
      "Epoch: 28 | Time: 0m 6s\n",
      "\tTrain Loss: 1.534 | Train PPL:   4.637\n",
      "\t Val. Loss: 3.809 |  Val. PPL:  45.103\n",
      "Epoch: 29 | Time: 0m 6s\n",
      "\tTrain Loss: 1.458 | Train PPL:   4.296\n",
      "\t Val. Loss: 3.830 |  Val. PPL:  46.081\n",
      "Epoch: 30 | Time: 0m 6s\n",
      "\tTrain Loss: 1.417 | Train PPL:   4.125\n",
      "\t Val. Loss: 3.820 |  Val. PPL:  45.603\n",
      "Epoch: 31 | Time: 0m 6s\n",
      "\tTrain Loss: 1.403 | Train PPL:   4.069\n",
      "\t Val. Loss: 3.824 |  Val. PPL:  45.776\n",
      "Epoch: 32 | Time: 0m 5s\n",
      "\tTrain Loss: 1.314 | Train PPL:   3.722\n",
      "\t Val. Loss: 3.871 |  Val. PPL:  47.970\n",
      "Epoch: 33 | Time: 0m 5s\n",
      "\tTrain Loss: 1.251 | Train PPL:   3.493\n",
      "\t Val. Loss: 3.869 |  Val. PPL:  47.893\n",
      "Epoch: 34 | Time: 0m 4s\n",
      "\tTrain Loss: 1.242 | Train PPL:   3.463\n",
      "\t Val. Loss: 3.879 |  Val. PPL:  48.367\n",
      "Epoch: 35 | Time: 0m 5s\n",
      "\tTrain Loss: 1.176 | Train PPL:   3.240\n",
      "\t Val. Loss: 4.021 |  Val. PPL:  55.741\n",
      "Epoch: 36 | Time: 0m 6s\n",
      "\tTrain Loss: 1.156 | Train PPL:   3.178\n",
      "\t Val. Loss: 3.943 |  Val. PPL:  51.583\n",
      "Epoch: 37 | Time: 0m 6s\n",
      "\tTrain Loss: 1.120 | Train PPL:   3.066\n",
      "\t Val. Loss: 3.933 |  Val. PPL:  51.064\n",
      "Epoch: 38 | Time: 0m 6s\n",
      "\tTrain Loss: 1.089 | Train PPL:   2.973\n",
      "\t Val. Loss: 3.980 |  Val. PPL:  53.501\n",
      "Epoch: 39 | Time: 0m 5s\n",
      "\tTrain Loss: 1.025 | Train PPL:   2.786\n",
      "\t Val. Loss: 4.052 |  Val. PPL:  57.489\n",
      "Epoch: 40 | Time: 0m 6s\n",
      "\tTrain Loss: 0.973 | Train PPL:   2.646\n",
      "\t Val. Loss: 4.041 |  Val. PPL:  56.872\n",
      "Epoch: 41 | Time: 0m 6s\n",
      "\tTrain Loss: 0.976 | Train PPL:   2.654\n",
      "\t Val. Loss: 4.109 |  Val. PPL:  60.883\n",
      "Epoch: 42 | Time: 0m 6s\n",
      "\tTrain Loss: 0.945 | Train PPL:   2.573\n",
      "\t Val. Loss: 4.135 |  Val. PPL:  62.490\n",
      "Epoch: 43 | Time: 0m 6s\n",
      "\tTrain Loss: 0.943 | Train PPL:   2.567\n",
      "\t Val. Loss: 4.169 |  Val. PPL:  64.652\n",
      "Epoch: 44 | Time: 0m 5s\n",
      "\tTrain Loss: 0.875 | Train PPL:   2.399\n",
      "\t Val. Loss: 4.235 |  Val. PPL:  69.081\n",
      "Epoch: 45 | Time: 0m 5s\n",
      "\tTrain Loss: 0.858 | Train PPL:   2.359\n",
      "\t Val. Loss: 4.180 |  Val. PPL:  65.369\n",
      "Epoch: 46 | Time: 0m 5s\n",
      "\tTrain Loss: 0.831 | Train PPL:   2.295\n",
      "\t Val. Loss: 4.236 |  Val. PPL:  69.118\n",
      "Epoch: 47 | Time: 0m 5s\n",
      "\tTrain Loss: 0.792 | Train PPL:   2.207\n",
      "\t Val. Loss: 4.296 |  Val. PPL:  73.392\n",
      "Epoch: 48 | Time: 0m 5s\n",
      "\tTrain Loss: 0.717 | Train PPL:   2.048\n",
      "\t Val. Loss: 4.389 |  Val. PPL:  80.595\n",
      "Epoch: 49 | Time: 0m 6s\n",
      "\tTrain Loss: 0.750 | Train PPL:   2.116\n",
      "\t Val. Loss: 4.338 |  Val. PPL:  76.572\n",
      "Epoch: 50 | Time: 0m 6s\n",
      "\tTrain Loss: 0.701 | Train PPL:   2.016\n",
      "\t Val. Loss: 4.438 |  Val. PPL:  84.577\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# 학습 실행\n",
    "N_EPOCHS = 50\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# 시간 측정용\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Validation loss가 가장 낮은 모델을 저장\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'seq2seq-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a3d1a",
   "metadata": {},
   "source": [
    "### 9. 결과: 모델 추론 (번역)\n",
    "\n",
    "학습된 모델을 사용하여 새로운 영어 문장을 한국어로 번역하는 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6146a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역(추론) 함수\n",
    "def translate_sentence(sentence, model, vocab_en, vocab_ko, tokenizer_en, device, max_len=50):\n",
    "    model.eval() # 평가 모드\n",
    "\n",
    "    # 1. 입력 문장 토큰화 및 전처리\n",
    "    tokens = [token.lower() for token in tokenizer_en(sentence)]\n",
    "    tokens = tokens + ['<eos>']\n",
    "    src_indexes = [vocab_en[token] for token in tokens]\n",
    "\n",
    "    # (src_len) -> (src_len, 1) : 배치 크기 1\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    # 2. 인코더\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "\n",
    "    # 3. 디코더\n",
    "    # <sos> 토큰으로 디코더 시작\n",
    "    trg_indexes = [SOS_IDX]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        # (1) -> (1, 1) : 배치 크기 1\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        trg_tensor = trg_tensor.unsqueeze(0) # (1, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor.squeeze(0), hidden)\n",
    "\n",
    "        # 가장 확률 높은 토큰 예측\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        # <eos> 토큰 만나면 종료\n",
    "        if pred_token == EOS_IDX:\n",
    "            break\n",
    "\n",
    "    # 4. 인덱스를 단어로 변환 (Vocabulary 사용)\n",
    "    trg_tokens = [vocab_ko.get_itos()[i] for i in trg_indexes]\n",
    "\n",
    "    # <sos> 제외하고 반환\n",
    "    return \" \".join(trg_tokens[1:-1]) # <sos>와 <eos> 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07b013d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 번역 테스트 ---\n",
      "원본 (Eng): I want to get a job that mixes work and play.\n",
      "정답 (Kor): 나는 일과 놀이가 섞인 직업을 갖고 싶다.\n",
      "번역 (Model): 나 는 <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "원본 (Eng): Children need to be fed.\n",
      "정답 (Kor): 어린이들은 먹어야만 한다.\n",
      "번역 (Model): <unk> 을 <unk> <unk> <unk> .\n",
      "\n",
      "원본 (Eng): Fantastic!\n",
      "정답 (Kor): 끝내주네!\n",
      "번역 (Model): <unk>\n",
      "\n",
      "원본 (Eng): Many people eat turkey on Christmas Day.\n",
      "정답 (Kor): 많은 사람들은 크리스마스 때 칠면조를 먹어.\n",
      "번역 (Model): 대부분 들 은 <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "원본 (Eng): I wanted to do something nice for you.\n",
      "정답 (Kor): 뭔가 너한테 좋은 것을 해주고 싶었어.\n",
      "번역 (Model): 너 한테 <unk> <unk> <unk> .\n",
      "\n",
      "원본 (Eng): A man is playing a guitar.\n",
      "번역 (Model): <unk> 은 <unk> <unk> <unk> .\n",
      "\n",
      "원본 (Eng): I know it\n",
      "번역 (Model): <unk>\n",
      "\n",
      "원본 (Eng): Hello\n",
      "번역 (Model): <unk> .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제: 번역 예제\n",
    "\n",
    "# 학습된 모델 로드\n",
    "model.load_state_dict(torch.load('seq2seq-model.pt'))\n",
    "\n",
    "# 검증 데이터셋에서 몇 개 샘플 뽑아서 테스트\n",
    "print(\"--- 번역 테스트 ---\")\n",
    "for i in range(5):\n",
    "    src, trg = valid_dataset[i]\n",
    "    translation = translate_sentence(src, model, vocab_en, vocab_ko, tokenize_en, device)\n",
    "\n",
    "    print(f\"원본 (Eng): {src}\")\n",
    "    print(f\"정답 (Kor): {trg}\")\n",
    "    print(f\"번역 (Model): {translation}\\n\")\n",
    "\n",
    "\n",
    "# 임의의 문장 테스트\n",
    "custom_sentence = \"A man is playing a guitar.\"\n",
    "translation = translate_sentence(custom_sentence, model, vocab_en, vocab_ko, tokenize_en, device)\n",
    "print(f\"원본 (Eng): {custom_sentence}\")\n",
    "print(f\"번역 (Model): {translation}\\n\")\n",
    "\n",
    "custom_sentence = \"I know it\"\n",
    "translation = translate_sentence(custom_sentence, model, vocab_en, vocab_ko, tokenize_en, device)\n",
    "print(f\"원본 (Eng): {custom_sentence}\")\n",
    "print(f\"번역 (Model): {translation}\\n\")\n",
    "\n",
    "custom_sentence = \"Hello\"\n",
    "translation = translate_sentence(custom_sentence, model, vocab_en, vocab_ko, tokenize_en, device)\n",
    "print(f\"원본 (Eng): {custom_sentence}\")\n",
    "print(f\"번역 (Model): {translation}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691c708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai5_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
