"""
ğŸ¯ FastAPI ì‹¤ìŠµ: Lifespan 
1. Lifespanì„ í™œìš©í•œ ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
2. ML ëª¨ë¸ì„ ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ ë¡œë”©í•˜ëŠ” íŒ¨í„´ ì´í•´
3. ì „ì—­ ì €ì¥ì†Œë¥¼ í™œìš©í•œ ëª¨ë¸ ê³µìœ  ë°©ì‹ í•™ìŠµ

ğŸ“Œ ì‹¤í–‰ ë°©ë²•:
uvicorn lab0.lifespan_test:app --reload
"""

# https://fastapi.tiangolo.com/advanced/events/
from fastapi import FastAPI
from contextlib import asynccontextmanager
import time

# Fake model loader
def load_model():
    time.sleep(3)
    return {"model": "fake-ml-model"}

# ì „ì—­ ëª¨ë¸ ì €ì¥ì†Œ
ml_models = {}  # global dict

# Lifespan: ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
@asynccontextmanager                # â‘  ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ë°ì½”ë ˆì´í„°
async def lifespan(app: FastAPI):
    # â‘¡ ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ë¶€ë¶„ (startup)
    print("====== ëª¨ë¸ë¡œë”©ì¤‘... ======")
    ml_models["sentiment"] = load_model()   # ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

    # â‘¢ ì—¬ê¸°ì„œ "ì¼ì‹œì •ì§€" â†’ ì„œë²„ê°€ ìš”ì²­ì„ ë°›ê¸° ì‹œì‘
    yield

    # â‘£ ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ë¶€ë¶„ (shutdown)
    print("ğŸ§¹ ëª¨ë¸ ë©”ëª¨ë¦¬ ì •ë¦¬")
    ml_models.clear()

app = FastAPI(lifespan=lifespan)

# API Endpoints
@app.get("/predict")
def predict(text: str):
    model = ml_models["sentiment"]
    return {
        "input": text,
        "prediction": "positive",
        "model": model["model"]
    }

@app.get("/bad")
def bad_example(text: str):
    print("--ëª¨ë¸ ë§¤ë²ˆ ë¡œë”© X")
    model = load_model()
    return {
        "input": text,
        "result": "ëŠë¦¼",
        "model": model["model"]
    } 