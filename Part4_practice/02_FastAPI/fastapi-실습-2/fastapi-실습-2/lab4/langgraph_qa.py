"""
ğŸ¯ FastAPI ì‹¤ìŠµ: LangGraph ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì—ì´ì „íŠ¸
1. LangGraph StateGraphë¥¼ í™œìš©í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±
2. ì¡°ê±´ë¶€ ì—£ì§€(Conditional Edges)ë¡œ ë™ì  ë¼ìš°íŒ… êµ¬í˜„
3. ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜(ì „ë¬¸ê°€/ì¹œêµ¬)ë¡œ ì‘ë‹µ
4. TypedDictë¥¼ ì‚¬ìš©í•œ ìƒíƒœ(State) ê´€ë¦¬ íŒ¨í„´

ğŸ“Œ ì‚¬ì „ ì¤€ë¹„:
1. pip install fastapi uvicorn langgraph langchain-openai langchain-core
2. .env íŒŒì¼ì— OPENAI_API_KEY=sk-xxx ì¶”ê°€

ğŸ“Œ ì‹¤í–‰ ë°©ë²•:
python ./lab4/langgraph_qa.py


ğŸ“Œ í…ŒìŠ¤íŠ¸ (Swagger UI):
http://localhost:8000/docs â†’ /smart_chat â†’ Try it out
message ì˜ˆì œ1: "íŒŒì´ì¬ì—ì„œ ë°ì½”ë ˆì´í„°ê°€ ë­ì•¼?"
message ì˜ˆì œ2: "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?"

ğŸ’¡ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¡°:
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  classifier â”‚ (ì§ˆë¬¸ ë¶„ë¥˜)
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ TECHNICAL          CASUAL   â”‚
            â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ tech_expert  â”‚              â”‚ friendly_botâ”‚
    â”‚ (ì‹œë‹ˆì–´ ê°œë°œì)â”‚              â”‚ (ì¹œì ˆí•œ ì¹œêµ¬) â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚                             â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                        [END]

"""

from fastapi import FastAPI
from pydantic import BaseModel
from typing import TypedDict, Literal

# LangGraph & LangChain Imports
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

# 1. ìƒíƒœ(State) ì •ì˜: ê·¸ë˜í”„ ë‚´ì—ì„œ ê³µìœ ë˜ëŠ” ë°ì´í„°
class AgentState(TypedDict):
    question: str
    classification: str
    response: str

# 2. ëª¨ë¸ ì„¤ì •
model = ChatOpenAI(model="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))

# --- ë…¸ë“œ(Nodes) ì •ì˜ ---
# ë…¸ë“œ 1: ì§ˆë¬¸ ë¶„ë¥˜ê¸° (Classifier)
def classify_input(state: AgentState):
    print(f"--- ë¶„ë¥˜ì¤‘: {state['question']}")
    prompt = ChatPromptTemplate.from_template(
        """ë‹¤ìŒ ì§ˆë¬¸ì„ 'TECHNICAL'(í”„ë¡œê·¸ë˜ë°/ì½”ë”©/ê¸°ìˆ  ê´€ë ¨) ë˜ëŠ” 'CASUAL'(ì¼ìƒ ëŒ€í™”/ì¸ì‚¬) ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
            ì§ˆë¬¸: {question}
            ê²°ê³¼:
        """
        )
    chain = prompt | model | StrOutputParser()
    result = chain.invoke({"question": state["question"]})

    # ê²°ê³¼ë¥¼ ê¹”ë”í•˜ê²Œ ì •ì œ
    classification = "TECHNICAL" if "TECHNICAL" in result.upper() else "CASUAL"
    return {"classification": classification}

# ë…¸ë“œ 2: ê¸°ìˆ  ì „ë¬¸ê°€ ë‹µë³€
def handle_technical(state: AgentState):
    print("=========== ê¸°ìˆ  ì „ë¬¸ê°€ ëª¨ë“œ")
    prompt = ChatPromptTemplate.from_template(
        "ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ íŒŒì´ì¬ ê°œë°œìì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì—„ê²©í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\nì§ˆë¬¸: {question}"
    )
    chain = prompt | model | StrOutputParser()
    return {"response": chain.invoke({"question": state['question']})}
   
# ë…¸ë“œ 3: ì¹œì ˆí•œ ì¹œêµ¬ ë‹µë³€
def handle_casual(state: AgentState):
    print("=========== ì¼ìƒ ëŒ€í™” ëª¨ë“œ")
    prompt = ChatPromptTemplate.from_template(
        "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¹œêµ¬ì…ë‹ˆë‹¤. ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ë”°ëœ»í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\nì§ˆë¬¸: {question}"
    )
    chain = prompt | model | StrOutputParser()
    return {"response": chain.invoke({"question": state['question']})}


# --- ê·¸ë˜í”„(Graph) êµ¬ì„± ---
workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("classifier", classify_input)
workflow.add_node("tech_expert", handle_technical)
workflow.add_node("friendly_bot", handle_casual)

# ì§„ì…ì  ì„¤ì •
workflow.set_entry_point("classifier")

# ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •
def decide_route(state: AgentState):
    if state["classification"] == "TECHNICAL":
        return "tech_expert"
    else:
        return "friendly_bot"
    
# ì¡°ê±´ë¶€ ì—£ì§€ ì—°ê²° (classifier -> tech_expert OR friendly_bot)
workflow.add_conditional_edges(
    "classifier",
    decide_route,
    {
        "tech_expert": "tech_expert",
        "friendly_bot": "friendly_bot"
    }
)

# ì¢…ë£Œ ì—£ì§€ ì—°ê²°
workflow.add_edge("tech_expert", END)
workflow.add_edge("friendly_bot", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼ (ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë³€í™˜)
app_graph = workflow.compile()


# --- FastAPI ì—”ë“œí¬ì¸íŠ¸ ---
class ChatRequest(BaseModel):
    message: str

@app.post("/smart_chat")
async def smart_chat(req: ChatRequest):
    inputs = {"question": req.message}
    result = await app_graph.ainvoke(inputs)    

    return {
        "type": result["classification"],
        "reply": result["response"]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)