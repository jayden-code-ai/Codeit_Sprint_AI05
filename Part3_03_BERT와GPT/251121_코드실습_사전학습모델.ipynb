{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59723a74",
   "metadata": {},
   "source": [
    "# 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f7c1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (1.11.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: filelock in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from accelerate) (2.7.1+cu118)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893d3998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33895a",
   "metadata": {},
   "source": [
    "# 1. 문장 생성(이어쓰기)\n",
    "- https://huggingface.co/docs/transformers/en/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d12713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cake was so delicious that when I told my mom that I was getting ready to take it out, she said, \"Oh, you've got to go, but you must also go to the bathroom in the middle of this one.\"\n",
      "\n",
      "She gave me one that tasted better than my other. She put it in my dresser and said to see the picture. We did, and eventually we settled down and enjoyed our time together. It's also a good reminder to be grateful for the\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "prompt = \"The cake was so delicious that\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0]\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34d5c2",
   "metadata": {},
   "source": [
    "# 2. 리뷰 감성 분석\n",
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3f3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 568454/568454 [00:02<00:00, 278529.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jhan21/amazon-food-reviews-dataset\")\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].select(range(1000)) # 일부만 선택\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0140603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Id': Value('int64'), 'ProductId': Value('string'), 'UserId': Value('string'), 'ProfileName': Value('string'), 'HelpfulnessNumerator': Value('int64'), 'HelpfulnessDenominator': Value('int64'), 'Score': Value('int64'), 'Time': Value('int64'), 'Summary': Value('string'), 'Text': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "# 어떤 컬럼이 label인지 확인\n",
    "print(dataset[\"train\"].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704c3e4",
   "metadata": {},
   "source": [
    "## 토크나이저 준비 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515a0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 16545.99 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 13543.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"Text\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a548e4",
   "metadata": {},
   "source": [
    "## 포맷 지정 및 label 컬럼 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476b5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 컬럼 이름을 labels로 지정\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"Score\", \"labels\")\n",
    "\n",
    "# 모델 학습을 위해 torch 텐서 포맷으로 지정\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41279f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(max(set(train_dataset[\"labels\"])))        # 중복 제거를 위해 set 사용\n",
    "print(min(set(train_dataset[\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfc8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 2813.82 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 2859.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 레이블을 0~4로 변경\n",
    "def shift_labels(example):\n",
    "    example[\"labels\"] -= 1\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(shift_labels)\n",
    "eval_dataset = eval_dataset.map(shift_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8714ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(max(set(train_dataset[\"labels\"])))\n",
    "print(min(set(train_dataset[\"labels\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c259bd",
   "metadata": {},
   "source": [
    "## 모델 로드 (문장 분류용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8793d621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2f897",
   "metadata": {},
   "source": [
    "## 평가 지표 정의 (정확도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2730828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 3.65MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred              # 둘 다 np.ndarray(댜차원 배열)\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377eebf3",
   "metadata": {},
   "source": [
    "## Trainer 설정 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e842e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "861d7c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.7923973083496094, metrics={'train_runtime': 111.2565, 'train_samples_per_second': 21.572, 'train_steps_per_second': 2.696, 'total_flos': 308362129304880.0, 'train_loss': 0.7923973083496094, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecf043",
   "metadata": {},
   "source": [
    "## 평가 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3134a1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6900\n",
      "예측 레이블: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Test Accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
    "\n",
    "# 예측 테스트\n",
    "text = \"This product is awesome!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model(**inputs)\n",
    "pred = outputs.logits.argmax(dim=1).item()\n",
    "print(\"예측 레이블:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce435cdf",
   "metadata": {},
   "source": [
    "## 3. 리뷰 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ece60",
   "metadata": {},
   "source": [
    "### 데이터셋불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad61a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/snap/amazon-fine-food-reviews?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242M/242M [00:07<00:00, 33.1MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Text': 'The product is advertised.  I was a little leery about buying it due to all the negative reviews about the dents during shipping, etc.  I received the 2 cases with no shipping delays.  A few of the peripheral cans had very minor dents but nothing worse than what I would purchase in a store.  No issues for me.', 'Summary': 'shipped just fine'}\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# 데이터셋 다운로드 및 불러오기\n",
    "path = kagglehub.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
    "df = pd.read_csv(f\"{path}/Reviews.csv\")\n",
    "df = df[['Text', 'Summary']].iloc[:50000]\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c43e1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Text]\n",
      "  평균 길이   : 103.0\n",
      "  90% 이하 길이: 207\n",
      "  최대 길이   : 2363\n",
      "\n",
      "[Summary]\n",
      "  평균 길이   : 5.8\n",
      "  90% 이하 길이: 10\n",
      "  최대 길이   : 63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Text 컬럼\n",
    "text_lengths = [\n",
    "    len(tokenizer(text=t, add_special_tokens=False)[\"input_ids\"])  # ← text=\n",
    "    for t in dataset[\"train\"][\"Text\"]\n",
    "    if t                                                          # None/빈 문자열 방어\n",
    "]\n",
    "\n",
    "# Summary 컬럼\n",
    "summary_lengths = [\n",
    "    len(tokenizer(text=s, add_special_tokens=False)[\"input_ids\"])  # ← text=\n",
    "    for s in dataset[\"train\"][\"Summary\"]\n",
    "    if s\n",
    "]\n",
    "\n",
    "def print_stats(name, lengths):\n",
    "    print(f\"[{name}]\")\n",
    "    print(f\"  평균 길이   : {np.mean(lengths):.1f}\")\n",
    "    print(f\"  90% 이하 길이: {np.percentile(lengths, 90):.0f}\")\n",
    "    print(f\"  최대 길이   : {np.max(lengths)}\\n\")\n",
    "\n",
    "print_stats(\"Text\", text_lengths)\n",
    "print_stats(\"Summary\", summary_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d084629",
   "metadata": {},
   "source": [
    "## 토크나이저 준비 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fffe2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 입력 길이 (인코더)\n",
    "max_input_length  = 256   # 90% 길이 207을 256(2의 거듭제곱)으로 여유 있게 상향\n",
    "\n",
    "# 요약 타깃 길이 (디코더)\n",
    "max_target_length = 16    # 90% 길이 10을 근사 16(8의 배수)으로 상향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d18faac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40000/40000 [00:03<00:00, 12771.64 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 11590.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # None · 숫자 · NaN 등을 깨끗한 문자열로 변환\n",
    "    texts     = [str(t) if t is not None else \"\" for t in examples[\"Text\"]]\n",
    "    summaries = [str(s) if s is not None else \"\" for s in examples[\"Summary\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text=texts,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        text=summaries,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,   # 필요 없으면 지워도 됨\n",
    ")\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset  = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebe0c5",
   "metadata": {},
   "source": [
    "## 모델 로드 (BART 요약용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f244a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a87b19",
   "metadata": {},
   "source": [
    "## 평가 지표 정의 (ROUGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3000d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72e340c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 6.14kB [00:00, 4.94MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219619e5",
   "metadata": {},
   "source": [
    "## Trainer 설정 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2834f79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 1:11:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.152100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.986000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden86/miniconda3/envs/jayden_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15000, training_loss=1.222372499593099, metrics={'train_runtime': 4271.4264, 'train_samples_per_second': 28.094, 'train_steps_per_second': 3.512, 'total_flos': 1.82920937472e+16, 'train_loss': 1.222372499593099, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer-2\",              # 결과 저장 폴더\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,     # 정확도 측정 함수\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16892e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delicious!\n"
     ]
    }
   ],
   "source": [
    "test_text = \"I absolutely loved this product. The flavor was amazing and I will definitely buy it again.\"\n",
    "\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "summary_ids = model.generate(**inputs, max_length=48, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ad732ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[원문] My husband (who, being Mexican, is very picky about his tortilla chips) and I absolutely love these!  The texture is light and crispy, rather than thick and crunchy. He actually usually prefers a very hearty, cruncy chip (Like El Ranchero), but the flavor of these is so fantastic that we're both thilled with them. The bean, rice and corn base makes them incredibly flavorful, and they have a touch of onion and garlic in addition to that. We go through an embarrassing amount of them.  I never, ever like plain chips, but these I can eat without anything else, although they're particularly amazing with a fresh salsa.  I highly recommend these!\n",
      "[요약] Best tortilla chips ever!\n",
      "\n",
      "[원문] Timothy's World Hazelnut Decaf Coffee is great tasting for decaf coffee.  Excellent service. Product arrived within 4 days after ordering.\n",
      "[요약] Great tasting decaf coffee\n",
      "\n",
      "[원문] Yes, these do contain an occasional stem or seed.  I just pull it off before eating and life goes on.  These are a great snack for weight watchers.\n",
      "[요약] Great Snack\n",
      "\n",
      "[원문] This came exactly as I expected and on time. It has a great flavor. I'm a very, very good cook and I can tell you that marinating overnight (as they suggest on the package) is not really necessary. A few hours is fine. That said, prepare as directed and the flavor is exactly like the familiar Chinese ribs you get in a restaurant. My only concern is the vibrant red of the marinade. There was a real scare about red dye in foods a few years back and I'm still a little wary of any product that uses dyes (such as red dye #3, used here). I'll probably use what I ordered but I doubt I'll use anymore because of the dye additive. Seriously, why does it have to be red? Why can't it just be great flavor?\n",
      "[요약] Great flavor!\n",
      "\n",
      "[원문] Well, they are Greenies.  Not much else to say about them besides it's a fantastic price.  They come in the green box shown, but inside is a re-sealable bag to keep them fresh which was really nice and actually a concern I had when I first purchased them.\n",
      "[요약] They are Greenies\n",
      "\n",
      "[원문] A strange taste, kind of like relish and jelly.  Not so good on toast but really good on ham and cheese melt.\n",
      "[요약] Strange taste\n",
      "\n",
      "[원문] Skittles are a great candy but for this product i would say do not buy it here, I have seen this same bag for $5.89 on sale and not on sale for $7.99 at some big chain stores. the candies themselves are fine and if you are thinking of getting a big bag you know what they taste like just don't overspend to get a big bag (price wise might be cheaper to buy a bunch of little bags)\n",
      "[요약] Skittles\n",
      "\n",
      "[원문] I have been using Gevalia Signature Blend Coffee, T-Discs for Tassimo and find it the best tasting coffee.  The ordering through Amazon is an easy experience and I never have a problem with Amazon.\n",
      "[요약] Best Tassimo Coffee\n",
      "\n",
      "[원문] This was very relaxing and when you want to nap, you can drink this and then take a nap.  It contains no caffeine and gives a nice break from every day stresses.\n",
      "[요약] Relaxative\n",
      "\n",
      "[원문] My husband loves pop chips, as a low-fat alternative to other potato chips.  They don't sell them at our regular grocery store, so we bought them on-line through Amazon.  The pop chips came on-time, packaged well, and it's cheaper to buy them in bulk like this!\n",
      "[요약] Love these chips!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. GPU 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. test 셋 선택\n",
    "test_texts = dataset[\"test\"][\"Text\"][:10]  # 예시로 10개만 추론\n",
    "\n",
    "# 3. 요약 결과 저장용 리스트\n",
    "summaries = []\n",
    "\n",
    "# 4. 문장 하나씩 요약\n",
    "for text in test_texts:\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    ).to(device)  # 입력도 GPU로 이동\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=48,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    summaries.append(summary)\n",
    "\n",
    "# 5. 출력 확인\n",
    "for i in range(len(test_texts)):\n",
    "    print(f\"[원문] {test_texts[i]}\")\n",
    "    print(f\"[요약] {summaries[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd30e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jayden_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
