{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocZ3kA2zVVi7"
   },
   "source": [
    "# COCO_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzKFE0sIsN4-"
   },
   "source": [
    "- Faster RCNN : https://pytorch.org/vision/0.9/_modules/torchvision/models/detection/faster_rcnn.html#fasterrcnn_resnet50_fpn\n",
    "\n",
    "- COCO API : https://github.com/cocodataset/cocoapi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8xEcI_9JePV"
   },
   "source": [
    "### ë°ì´í„° ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA57ju6MY6b0"
   },
   "source": [
    "MS COCO ë°ì´í„°ì…‹ì€ ì•½ 328000ìž¥ì˜ ì´ë¯¸ì§€ì™€ 80ê°œì˜ í´ëž˜ìŠ¤ë¡œ ì´ë£¨ì–´ì ¸ìžˆìœ¼ë‚˜, ì›Œë‚™ ëŒ€ê·œëª¨ì´ê¸° ë•Œë¬¸ì— ê°œì™€ ê³ ì–‘ì´ í´ëž˜ìŠ¤ë¥¼ ì†Œê·œëª¨ë¡œ ìƒ˜í”Œë§í•´ ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12588,
     "status": "ok",
     "timestamp": 1758845134614,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "x7yOj-qrVAme",
    "outputId": "14a669a3-047e-4acc-bb3c-ffc52506b3ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (6.32.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages (from kaggle) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45513,
     "status": "ok",
     "timestamp": 1758845266598,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "Xoc5h2l4VqaA",
    "outputId": "bac6ba78-b93b-47e8-938b-4d12eb5cb64e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayden/Projects/my-first-py/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/s076923/pytorch-transformer?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 916M/916M [01:07<00:00, 14.3MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/jayden/.cache/kagglehub/datasets/s076923/pytorch-transformer/versions/4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"s076923/pytorch-transformer\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1758845273268,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "eQ4J21H2WDiK",
    "outputId": "a8df6965-deef-4b2e-9b10-d25d30101282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./4' í´ë”ê°€ ì´ë¯¸ ì¡´ìž¬í•˜ë¯€ë¡œ ì‚­ì œí•©ë‹ˆë‹¤. ðŸ—‘ï¸\n",
      "'./4' í´ë”ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤. âœ…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# kagglehubë¡œ ë‹¤ìš´ë¡œë“œí•œ ê²½ë¡œê°€ 'path' ë³€ìˆ˜ì— ìžˆë‹¤ê³  ê°€ì •\n",
    "# path = '/Users/jayden/.cache/kagglehub/datasets/s076923/pytorch-transformer/versions/4'\n",
    "\n",
    "# 1. ì˜®ê¸¸ í´ë”ì˜ ì´ë¦„(ì˜ˆ: '4')ê³¼ ë„ì°©í•  ê²½ë¡œë¥¼ ë¯¸ë¦¬ ì •ì˜\n",
    "folder_name = os.path.basename(path)\n",
    "destination_path = os.path.join('./', folder_name)\n",
    "\n",
    "# 2. ë§Œì•½ ë„ì°©í•  ê²½ë¡œì— í´ë”ê°€ ì´ë¯¸ ìžˆë‹¤ë©´, ë¨¼ì € ì‚­ì œ\n",
    "if os.path.exists(destination_path):\n",
    "    print(f\"'{destination_path}' í´ë”ê°€ ì´ë¯¸ ì¡´ìž¬í•˜ë¯€ë¡œ ì‚­ì œí•©ë‹ˆë‹¤. ðŸ—‘ï¸\")\n",
    "    shutil.rmtree(destination_path) # í´ë”ì™€ ë‚´ìš©ë¬¼ ëª¨ë‘ ì‚­ì œ\n",
    "\n",
    "# 3. ì´ì œ ì•ˆì‹¬í•˜ê³  í´ë” ì´ë™\n",
    "shutil.move(path, './')\n",
    "print(f\"'{destination_path}' í´ë”ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤. âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1758845480808,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "-eC2yvdBWQQy"
   },
   "outputs": [],
   "source": [
    "# ìž‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/jayden/Projects/my-first-py/data/datasets\")        # ìž‘ì—…í•  ë°ì´í„°ì…‹ í´ë”ë¡œ ì´ë™ (ì‹¤í–‰ í™˜ê²½ì— ë”°ë¼ ê²½ë¡œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ì´ ìžˆìŒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeYMLrjaJioI"
   },
   "source": [
    "### ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUYulZzfOL9o"
   },
   "source": [
    "COCO ë°ì´í„°ëŠ” \"ID\"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì‹±ì„ í•´ì•¼ í•©ë‹ˆë‹¤.    \n",
    "images:\n",
    "\n",
    "- ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸\n",
    "- ê° í•­ëª©ì€ ì´ë¯¸ì§€ì˜ ê³ ìœ  id, íŒŒì¼ëª…, ë„ˆë¹„, ë†’ì´ ë“±ì˜ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "annotations:\n",
    "\n",
    "- ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ì–´ë…¸í…Œì´ì…˜ ì •ë³´(ì˜ˆ: ë°”ìš´ë”© ë°•ìŠ¤, ë¼ë²¨)ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "categories:\n",
    "\n",
    "- ê°ì²´ì˜ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwYOOLnmN--Q"
   },
   "source": [
    "```\n",
    "{\n",
    "\t\"info\": {\n",
    "\t\t\"year\": 2021,\n",
    "\t\t\"version\": \"1.0\",\n",
    "\t\t\"description\": \"For object detection\",\n",
    "\t\t\"date_created\": \"2021\"\n",
    "\t},\n",
    "\t\"images\": [\n",
    "\t\t{\n",
    "\t\t\t\"date_captured\": \"2021\",\n",
    "\t\t\t\"file_name\": \"000000000001.jpg\",\n",
    "\t\t\t\"id\": 1,\n",
    "\t\t\t\"height\": 480,\n",
    "\t\t\t\"width\": 640\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"date_captured\": \"2021\",\n",
    "\t\t\t\"file_name\": \"000000000002.jpg\",\n",
    "\t\t\t\"id\": 2,\n",
    "\t\t\t\"height\": 426,\n",
    "\t\t\t\"width\": 640\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"date_captured\": \"2021\",\n",
    "\t\t\t\"file_name\": \"000000000003.jpg\",\n",
    "\t\t\t\"id\": 3,\n",
    "\t\t\t\"height\": 428,\n",
    "\t\t\t\"width\": 640\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"date_captured\": \"2021\",\n",
    "\t\t\t\"file_name\": \"000000000004.jpg\",\n",
    "\t\t\t\"id\": 4,\n",
    "\t\t\t\"height\": 425,\n",
    "\t\t\t\"width\": 640\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"date_captured\": \"2021\",\n",
    "\t\t\t\"file_name\": \"000000000005.jpg\",\n",
    "\t\t\t\"id\": 5,\n",
    "\t\t\t\"height\": 640,\n",
    "\t\t\t\"width\": 481\n",
    "\t\t}\n",
    "\t],\n",
    "\t\"licenses\": [\n",
    "\t\t{\n",
    "\t\t\t\"id\": 1,\n",
    "\t\t\t\"name\": \"GNU General Public License v3.0\",\n",
    "\t\t\t\"url\": \"https://github.com/zhiqwang/yolov5-rt-stack/blob/master/LICENSE\"\n",
    "\t\t}\n",
    "\t],\n",
    "\t\"type\": \"instances\",\n",
    "\t\"annotations\": [\n",
    "\t\t{\n",
    "\t\t\t\"segmentation\": [\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t1.0799999999999272,\n",
    "\t\t\t\t\t187.69008000000002,\n",
    "\t\t\t\t\t612.66976,\n",
    "\t\t\t\t\t187.69008000000002,\n",
    "\t\t\t\t\t612.66976,\n",
    "\t\t\t\t\t473.53008000000005,\n",
    "\t\t\t\t\t1.0799999999999272,\n",
    "\t\t\t\t\t473.53008000000005\n",
    "\t\t\t\t]\n",
    "\t\t\t],\n",
    "\t\t\t\"area\": 174816.81699840003,\n",
    "\t\t\t\"iscrowd\": 0,\n",
    "\t\t\t\"image_id\": 1,\n",
    "\t\t\t\"bbox\": [\n",
    "\t\t\t\t1.0799999999999272,\n",
    "\t\t\t\t187.69008000000002,\n",
    "\t\t\t\t611.5897600000001,\n",
    "\t\t\t\t285.84000000000003\n",
    "\t\t\t],\n",
    "\t\t\t\"category_id\": 19,\n",
    "\t\t\t\"id\": 1\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"segmentation\": [\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t311.73024,\n",
    "\t\t\t\t\t4.310159999999996,\n",
    "\t\t\t\t\t631.0102400000001,\n",
    "\t\t\t\t\t4.310159999999996,\n",
    "\t\t\t\t\t631.0102400000001,\n",
    "\t\t\t\t\t232.99032,\n",
    "\t\t\t\t\t311.73024,\n",
    "\t\t\t\t\t232.99032\n",
    "\t\t\t\t]\n",
    "\t\t\t],\n",
    "\t\t\t\"area\": 73013.00148480001,\n",
    "\t\t\t\"iscrowd\": 0,\n",
    "\t\t\t\"image_id\": 1,\n",
    "\t\t\t\"bbox\": [\n",
    "\t\t\t\t311.73024,\n",
    "\t\t\t\t4.310159999999996,\n",
    "\t\t\t\t319.28000000000003,\n",
    "\t\t\t\t228.68016\n",
    "\t\t\t],\n",
    "\t\t\t\"category_id\": 50,\n",
    "\t\t\t\"id\": 2\n",
    "\t\t},\n",
    "        ],\n",
    "\"categories\": [\n",
    "\t\t{\n",
    "\t\t\t\"id\": 1,\n",
    "\t\t\t\"name\": \"0\",\n",
    "\t\t\t\"supercategory\": \"0\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"id\": 2,\n",
    "\t\t\t\"name\": \"1\",\n",
    "\t\t\t\"supercategory\": \"1\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"id\": 3,\n",
    "\t\t\t\"name\": \"2\",\n",
    "\t\t\t\"supercategory\": \"2\"\n",
    "\t\t},\n",
    "        ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1758847882780,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "DX_UFW-ZXONq"
   },
   "outputs": [],
   "source": [
    "import os              # íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import json            # JSON íŒŒì¼ì„ ì½ê³  ì“°ê¸° ìœ„í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import torch           # ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ PyTorch (í…ì„œ ì—°ì‚° ë“±)\n",
    "from PIL import Image  # ì´ë¯¸ì§€ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from torch.utils.data import Dataset  # PyTorchì˜ Dataset í´ëž˜ìŠ¤ë¥¼ ìƒì†ë°›ê¸° ìœ„í•œ ëª¨ë“ˆ\n",
    "\n",
    "# coco ë°ì´í„°ì…‹ì˜ JSON íŒŒì¼ì„ ì§ì ‘ íŒŒì‹±í•˜ê¸° ìœ„í•œ ì‚¬ìš©ìž ì •ì˜ í´ëž˜ìŠ¤\n",
    "class CustomCOCO:\n",
    "    def __init__(self, annotation_file):\n",
    "        \"\"\"\n",
    "        CustomCOCO í´ëž˜ìŠ¤ ì´ˆê¸°í™” í•¨ìˆ˜.\n",
    "        :param annotation_file: COCO ë°ì´í„°ì…‹ì˜ ì–´ë…¸í…Œì´ì…˜(JSON) íŒŒì¼ ê²½ë¡œ\n",
    "        \"\"\"\n",
    "        # ðŸ’¾ JSON íŒŒì¼ì„ ì—´ì–´ì„œ ë°ì´í„°ë¥¼ ì½ìŠµë‹ˆë‹¤.\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        # ðŸžï¸ ì´ë¯¸ì§€ ì •ë³´ë¥¼ 'id'ë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "        # ðŸ“ ê° ì´ë¯¸ì§€ ì •ë³´ëŠ” JSON íŒŒì¼ì˜ \"images\" ë¦¬ìŠ¤íŠ¸ì— ì €ìž¥ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n",
    "        self.images = {img[\"id\"]: img for img in self.data.get(\"images\", [])}\n",
    "\n",
    "        # ì–´ë…¸í…Œì´ì…˜(annotation) ì •ë³´ë¥¼ ì´ë¯¸ì§€ idë³„ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.\n",
    "        # JSON íŒŒì¼ì˜ \"annotations\" ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©°, ê° ì–´ë…¸í…Œì´ì…˜ì„ í•´ë‹¹ ì´ë¯¸ì§€ id ì•„ëž˜ì— ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "        self.annotations = {}\n",
    "        for ann in self.data.get(\"annotations\", []):\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.annotations:\n",
    "                self.annotations[img_id] = []\n",
    "            self.annotations[img_id].append(ann)\n",
    "\n",
    "        # ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ 'id'ë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "        # JSON íŒŒì¼ì˜ \"categories\" ë¦¬ìŠ¤íŠ¸ì— ê° ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ ì €ìž¥ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n",
    "        self.cats = {cat['id']: cat for cat in self.data.get(\"categories\", [])}\n",
    "\n",
    "    def loadImgs(self, ids):\n",
    "        \"\"\"\n",
    "        ì£¼ì–´ì§„ ì´ë¯¸ì§€ id ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ì •ë³´(ë”•ì…”ë„ˆë¦¬)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        :param ids: ì´ë¯¸ì§€ id ë¦¬ìŠ¤íŠ¸\n",
    "        :return: ì£¼ì–´ì§„ ì´ë¯¸ì§€ idì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        return [self.images[i] for i in ids if i in self.images]\n",
    "\n",
    "    def getAnnIds(self, imgIds):\n",
    "        \"\"\"\n",
    "        ì£¼ì–´ì§„ ì´ë¯¸ì§€ idë“¤ì— ëŒ€í•´, ì–´ë…¸í…Œì´ì…˜ idë“¤ì„ ëª¨ë‘ ëª¨ì•„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        :param imgIds: ì´ë¯¸ì§€ id ë¦¬ìŠ¤íŠ¸\n",
    "        :return: ì–´ë…¸í…Œì´ì…˜ idë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        ann_ids = []\n",
    "        for img_id in imgIds:\n",
    "            if img_id in self.annotations:\n",
    "                ann_ids.extend([ann['id'] for ann in self.annotations[img_id]])\n",
    "        return ann_ids\n",
    "\n",
    "    def loadAnns(self, annIds):\n",
    "        \"\"\"\n",
    "        ì£¼ì–´ì§„ ì–´ë…¸í…Œì´ì…˜ id ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì–´ë…¸í…Œì´ì…˜ ì •ë³´(ë”•ì…”ë„ˆë¦¬)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        :param annIds: ì–´ë…¸í…Œì´ì…˜ id ë¦¬ìŠ¤íŠ¸\n",
    "        :return: ì£¼ì–´ì§„ ì–´ë…¸í…Œì´ì…˜ idì— í•´ë‹¹í•˜ëŠ” ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        anns = []\n",
    "        # ëª¨ë“  ì–´ë…¸í…Œì´ì…˜ì„ ìˆœíšŒí•˜ë©´ì„œ idê°€ annIdsì— í¬í•¨ëœ ê²ƒë§Œ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "        for ann in self.data.get(\"annotations\", []):\n",
    "            if ann['id'] in annIds:\n",
    "                anns.append(ann)\n",
    "        return anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1758850489216,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "MwaVqkgzaqY8"
   },
   "outputs": [],
   "source": [
    "# PyTorch Dataset í´ëž˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ COCO ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í´ëž˜ìŠ¤\n",
    "class COCODataset(Dataset):\n",
    "    def __init__(self, root, train, transform=None):\n",
    "        \"\"\"\n",
    "        COCODataset í´ëž˜ìŠ¤ ì´ˆê¸°í™” í•¨ìˆ˜.\n",
    "        :param root: COCO ë°ì´í„°ì…‹ì˜ ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        :param train: ë°ì´í„°ì…‹ì´ 'train'ì¸ì§€ 'val'ì¸ì§€ë¥¼ êµ¬ë¶„\n",
    "        :Param transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë³€í™˜ì„ ìœ„í•œ í•¨ìˆ˜(ì˜ˆ: tensor ë³€í™˜)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # í•™ìŠµ ë°ì´í„°ë©´ 'train' í´ë”//ê²€ì¦ë°ì´í„°ë©´'val'í´ë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        directory = \"train\" if train else \"val\"\n",
    "        # annotation íŒŒì¼ì˜ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        annotations_file = os.path.join(root, \"annotations\", f'{directory}_annotations.json')\n",
    "\n",
    "        # pycocotools ëŒ€ì‹  ì‚¬ìš©ìž ì •ì˜ CustomCOCO í´ëž˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–´ë…¸í…Œì´ì…˜ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "        self.coco = CustomCOCO(annotations_file)\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì €ìž¥ëœ í¬ë” ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "        self.imge_path = os.path.join(root, directory)\n",
    "        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ transform í•¨ìˆ˜ ì €ìž¥(í•„ìš”í•œ ê²½ìš° ì‚¬ìš©)\n",
    "        self.transform = transform\n",
    "\n",
    "        # COCO ë°ì´í„°ì…‹ì˜ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "        # 0ë²ˆì€ ë°°ê²½('background')ìœ¼ë¡œ ì´ˆê¸°í™” í•©ë‹ˆë‹¤.\n",
    "        self.categories = {0: 'background'}\n",
    "        for cat_id, cat in self.coco.cats.items():\n",
    "            self.categories[cat_id] = cat['name']\n",
    "\n",
    "        # ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ë¥¼ ë¡œë“œí•˜ì—¬ Data ë¦¬ìŠ¤íŠ¸ì— ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        COCO ë°ì´í„°ë„·ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì´ë¯¸ì§€ì™€ í•´ë‹¹ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "        :return: (ì´ë¯¸ì§€, target)ë¡œë“œëœ ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        # self.coco.imagesëŠ” ì´ë¯¸ì§€ idë¥¼ í‚¤ë¡œ ê°€ì§€ëŠ” ë”•ì…”ë„ˆë¦¬ìž…ë‹ˆë‹¤.\n",
    "        for _id, img_info in self.coco.images.items():\n",
    "            # ðŸ”– ì´ë¯¸ì§€ íŒŒì¼ì˜ ì´ë¦„ ì¶”ì¶œ\n",
    "            file_name = img_info['file_name']\n",
    "            # ðŸ–¼ï¸ ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„±\n",
    "            image_path = os.path.join(self.imge_path, file_name)\n",
    "            # ðŸŽ¨ PILì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ë¥¼ RGB ëª¨ë“œë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "            boxes = []      # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œë£Œë¥¼ ì €ìž¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "            labels = []     # ë°”ìš´ë”œ ë°•ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì¹´í…Œê³ ë¦¬ idë¥¼ ì €ìž¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "            # í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "            anns = self.coco.annotations.get(_id, [])\n",
    "            for ann in anns:\n",
    "                # ì–´ë…¸í…Œì´ì…˜ì—ì„œ [x, y, width, height] ì •ë³´ë¥¼ ê°€ì ¸ì˜´\n",
    "                x, y, w, h = ann['bbox']\n",
    "                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ [x_min, y_min, x_max, y_max] í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "                boxes.append([x, y, x + w, y + h])\n",
    "                # ì–´ë…¸í…Œì´ì…˜ì˜ ì¹´í…Œê³ ë¦¬ idë¥¼ labels ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "                labels.append(ann['category_id'])\n",
    "\n",
    "            # target ë”•ì…”ë„ˆë¦¬ì— ì´ë¯¸ì§€ id, ë°”ìš´ë”© ë°•ìŠ¤, ë¼ë²¨ ì •ë³´ë¥¼ tensor í˜•íƒœë¡œ ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "            target = {\n",
    "                'image_id': torch.LongTensor([_id]),\n",
    "                'boxes': torch.FloatTensor(boxes),\n",
    "                'labels': torch.LongTensor(labels)\n",
    "            }\n",
    "\n",
    "            # data ë¦¬ìŠ¤íŠ¸ì— ì´ë¯¸ì§€ì™€ targetì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "            data.append((image, target))\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Datasetì˜ íŠ¹ì • indexì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ì™€ targetì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        :param index: ë°ì´í„°ì…‹ ë‚´ ìƒ˜í”Œì˜ ì¸ë±ìŠ¤\n",
    "        :return: ì´ë¯¸ì§€ì™€ target íŠœí”Œ\n",
    "        \"\"\"\n",
    "        image, target = self.data[index]\n",
    "        # ë§Œì•½ ì „ì²˜ë¦¬ í•¨ìˆ˜(transform)ê°€ ì§€ì •ë˜ì–´ ìžˆë‹¤ë©´ ì´ë¯¸ì§€ì— ì ìš©í•©ë‹ˆë‹¤.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        ë°ì´í„°ì…‹ì˜ ì´ ìƒ˜í”Œ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        :return: ë°ì´í„°ì…‹ì˜ ì´ ìƒ˜í”Œ ìˆ˜\n",
    "        \"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 23727,
     "status": "ok",
     "timestamp": 1758850514219,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "2lxTiid4dJph"
   },
   "outputs": [],
   "source": [
    "# torchvision ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë„êµ¬ì™€ DataLoaderë¥¼ ìž„í¬íŠ¸ í•©ë‹ˆë‹¤.\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ë°°ì¹˜ ë°ì´í„°ë¥¼ ìƒì„±í•  ë•Œ, ê° ë°°ì¹˜ë§ˆë‹¤ ë°ì´í„°ë¥¼ íŠœí”Œ í˜•íƒœë¡œ ë¬¶ì–´ì£¼ëŠ” í•¨ìˆ˜\n",
    "# coco ë°ì´í„° ì…‹ì€ ì´ë¯¸ì§€ ë‚´ì— ì—¬ëŸ¬ ê°ì²´ ì •ë³´ê°€ ë‹´ê¸¸ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ, ë°ì´í„°ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìžˆìŒ.\n",
    "def collator(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬: PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³ , ë°ì´í„° íƒ€ìž…ì„ floatì˜¤ë¡œ ë³€í™˜\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(dtype=torch.float)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸(ê²€ì¦) ë°ì´í„°ë¥¼ ìœ„í•œ COCOë°ì´í„°ì…‹ ê°ì²´ ìƒì„±\n",
    "train_dataset = COCODataset(\"/Users/jayden/Projects/my-first-py/data/datasets/coco\", train=True, transform=transform)\n",
    "test_dataset = COCODataset(\"/Users/jayden/Projects/my-first-py/data/datasets/coco\", train=False, transform=transform)\n",
    "\n",
    "# DataLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë°°ì¹˜ê°€ ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=4, shuffle=True, drop_last=True, collate_fn=collator\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=4, shuffle=False, drop_last=False, collate_fn=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1758850518828,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "ZBTo5cmXp6p8",
    "outputId": "acaf1286-0595-48d1-d2df-c7184a1037a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0235,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0157, 0.0118, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0078, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0078, 0.1647, 0.2275,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.2157, 0.2941,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0039, 0.0118, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0235, 0.2902, 0.3961,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4000, 0.5490,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " {'image_id': tensor([374990]),\n",
       "  'boxes': tensor([[242.1200, 182.9700, 427.7500, 399.7300]]),\n",
       "  'labels': tensor([2])})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[101]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upRgblXcOxVK"
   },
   "source": [
    "##### Custom Collatorê°€ í•„ìš”í•œ ì´ìœ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrerZoZaPdBT"
   },
   "source": [
    "ì•„ëž˜ì— ê¸°ë³¸ collate í•¨ìˆ˜ì˜ ì¶œë ¥ê³¼ custom collateë¥¼ ì ìš©í•œ ìµœì¢… ì¶œë ¥ í˜•íƒœë¥¼ ìš”ì•½í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- **ê¸°ë³¸ collate í•¨ìˆ˜ (ì›ëž˜ í˜•íƒœ):**\n",
    "  - **ì¶œë ¥:**  \n",
    "    - **ì´ë¯¸ì§€ í…ì„œ:** ëª¨ë“  ì´ë¯¸ì§€ê°€ ë™ì¼í•œ í¬ê¸°ë¼ë©´, ìžë™ìœ¼ë¡œ ìŠ¤íƒë˜ì–´ í•˜ë‚˜ì˜ í…ì„œë¡œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.  \n",
    "      ì˜ˆ: `(batch_size, channels, height, width)`\n",
    "    - **íƒ€ê²Ÿ(ë¼ë²¨) í…ì„œ/ë”•ì…”ë„ˆë¦¬:** ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ìŠ¤íƒ ë˜ëŠ” í…ì„œ í˜•íƒœë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "  - **ë¬¸ì œì :**  \n",
    "    - ì´ë¯¸ì§€ë‚˜ íƒ€ê²Ÿì˜ í¬ê¸°ê°€ ì„œë¡œ ë‹¤ë¥´ë©´ ìŠ¤íƒí•˜ëŠ” ê³¼ì •ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "- **Custom collate ì ìš© í›„ (ìµœì¢… ì›í•˜ëŠ” í˜•íƒœ):**\n",
    "  - **ì¶œë ¥:**  \n",
    "    - **ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸:** ê° ì´ë¯¸ì§€ê°€ ê°œë³„ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¹ë‹ˆë‹¤.  \n",
    "      ì˜ˆ: `(image1, image2, ...)`\n",
    "    - **íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸:** ê° ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” íƒ€ê²Ÿì´ ê°œë³„ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¹ë‹ˆë‹¤.  \n",
    "      ì˜ˆ: `(target1, target2, ...)`\n",
    "  - **í˜•íƒœ ìš”ì•½:**  \n",
    "    - ìµœì¢… ë°°ì¹˜ì˜ ì¶œë ¥ì€ **((ì´ë¯¸ì§€1, ì´ë¯¸ì§€2, ...), (target1, target2, ...))** í˜•íƒœë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "  - **ìž¥ì :**  \n",
    "    - ì´ë¯¸ì§€ë‚˜ íƒ€ê²Ÿì´ ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì—¬ë„ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ìˆ˜ ìžˆì–´, ëª¨ë¸ ìž…ë ¥ ì „ì— ì ì ˆí•œ ì „ì²˜ë¦¬(ì˜ˆ: íŒ¨ë”©)ë¥¼ ì ìš©í•˜ê±°ë‚˜, ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë ‡ê²Œ custom collateë¥¼ ì‚¬ìš©í•˜ë©´ ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë°°ì¹˜ë¡œ ë¬¶ì–´ ëª¨ë¸ì— ìž…ë ¥í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1758851968997,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "kefl3SjpqXFI",
    "outputId": "8020f2e0-2367-452f-da30-174f5a4f94c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ë³¸ collate í•¨ìˆ˜ ì‚¬ìš©ì‹œ Error: stack expects each tensor to be equal size, but got [3, 300, 300] at entry 0 and [3, 400, 400] at entry 1\n"
     ]
    }
   ],
   "source": [
    "# collatorë¥¼ ì“°ëŠ” ì´ìœ \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "##### ìƒ˜í”Œ ë°ì´í„° ìƒì„± #####\n",
    "# ë‘ ê°œì˜ ìƒ˜í”Œ ì´ë¯¸ì§€ (ê°ê° ë‹¤ë¥¸ í¬ê¸°ì˜ í…ì„œ)\n",
    "image1 = torch.randn(3, 300, 300) # ch3, h300, w300\n",
    "target1 = {\n",
    "    \"boxes\": torch.tensor([[50, 50, 200, 200]], dtype=torch.float32),\n",
    "    \"labels\": torch.tensor([1])\n",
    "}\n",
    "\n",
    "image2 = torch.randn(3, 400, 400)  # ì±„ë„ 3, ë†’ì´ 400, ë„ˆë¹„ 400\n",
    "target2 = {\n",
    "    \"boxes\": torch.tensor([[100, 100, 350, 350], [30, 30, 100, 100]], dtype=torch.float32),  # ë‘ ê°œì˜ ë°•ìŠ¤\n",
    "    \"labels\": torch.tensor([2, 3])\n",
    "}\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸\n",
    "sample_data = [(image1, target1), (image2, target2)]\n",
    "\n",
    "###### ê¸°ë³¸ collator í•¨ìˆ˜ ######\n",
    "# ê¸°ë³¸ collate í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” DataLoader\n",
    "loader_without_collator = DataLoader(sample_data, batch_size=2)\n",
    "\n",
    "#ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´, ì´ë¯¸ì§€ í…ì„œë¥¼ ìŠ¤íƒí•˜ëŠ” ê³¼ì •ì—ì„œ í¬ê¸°ê°€ ë‹¬ë¼ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    for batch in loader_without_collator:\n",
    "        # batchëŠ” (images, targets) í˜•íƒœê°€ ë˜ì–´ì•¼í•¨\n",
    "        images, targets = batch\n",
    "        print(\"Batch images shape:\", images.shape)\n",
    "        print(\"Batch targets:\", targets)\n",
    "except Exception as e:\n",
    "    print(\"ê¸°ë³¸ collate í•¨ìˆ˜ ì‚¬ìš©ì‹œ Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1758852432004,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "ED6z6Nczvy7B",
    "outputId": "9e5ee4b6-b502-4329-8195-b5c0091e1ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°°ì¹˜ ì´ë¯¸ì§€ ê°œìˆ˜ :  2\n",
      "ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í¬ê¸° :  torch.Size([3, 300, 300])\n",
      "ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ í¬ê¸° :  torch.Size([3, 400, 400])\n",
      "ë°°ì¹˜ target ì˜ˆì‹œ :  {'boxes': tensor([[ 50.,  50., 200., 200.]]), 'labels': tensor([1])}\n",
      "ë°°ì¹˜ target ì˜ˆì‹œ :  {'boxes': tensor([[100., 100., 350., 350.],\n",
      "        [ 30.,  30., 100., 100.]]), 'labels': tensor([2, 3])}\n"
     ]
    }
   ],
   "source": [
    "###### Custom Collate ######\n",
    "'''custom collatorë¥¼ ì‚¬ìš©í•˜ë©´, ê° ìƒ˜í”Œì„ ê°œë³„ì ìœ¼ë¡œ ë¬¶ì–´ì„œ ë°°ì¹˜ë¥¼ êµ¬ì„±í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "ì¦‰, ê° ë°°ì¹˜ëŠ” (ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸, target ë¦¬ìŠ¤íŠ¸) í˜•íƒœê°€ ë˜ì–´, ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.'''\n",
    "\n",
    "# custom collator: ê° ìƒ˜í”Œì„ (ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸, target ë¦¬ìŠ¤íŠ¸) í˜•íƒœë¡œ ë¬¶ì–´ì¤ë‹ˆë‹¤.\n",
    "def collator(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# custom collatorë¥¼ ì‚¬ìš©í•˜ëŠ” DataLoader\n",
    "loader_without_collator = DataLoader(sample_data, batch_size=2, collate_fn=collator)\n",
    "\n",
    "for batch in loader_without_collator:\n",
    "    images, targets = batch\n",
    "    print(\"ë°°ì¹˜ ì´ë¯¸ì§€ ê°œìˆ˜ : \", len(images))\n",
    "    print(\"ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í¬ê¸° : \", images[0].shape)\n",
    "    print(\"ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ í¬ê¸° : \", images[1].shape)\n",
    "    print(\"ë°°ì¹˜ target ì˜ˆì‹œ : \", targets[0])\n",
    "    print(\"ë°°ì¹˜ target ì˜ˆì‹œ : \", targets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQp3zV67xzq2"
   },
   "source": [
    "## ëª¨ë¸ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10481,
     "status": "ok",
     "timestamp": 1758853176925,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "FzF96zR4xkAm",
    "outputId": "cfc4bd87-ad9d-4563-a873-9d738b39e026"
   },
   "outputs": [],
   "source": [
    "# torchvision ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ ê´€ë ¨ ëª¨ë“ˆì„ ìž„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "from torchvision import models\n",
    "from torchvision import ops\n",
    "from torchvision.models.detection import rpn\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "# ì‚¬ì „ í•™ìŠµëœ VGG16 ëª¨ë¸ì˜ feature extractor(íŠ¹ì§• ì¶”ì¶œê¸°)ë¥¼ backboneìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "backbone = models.vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").features\n",
    "backbone.out_channels = 512  # backboneì˜ ì¶œë ¥ ì±„ë„ ìˆ˜ ì„¤ì •\n",
    "\n",
    "# RPN(Region Proposal Network)ì—ì„œ ì‚¬ìš©í•  ì•µì»¤ ìƒì„±ê¸° ì„¤ì •\n",
    "anchor_generator = rpn.AnchorGenerator(\n",
    "    sizes=((32, 64, 128, 256, 512),),       # ê° ìŠ¤ì¼€ì¼ë³„ ì•µì»¤ í¬ê¸° ì§€ì •\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),)         # ê° ì•µì»¤ì˜ ê°€ë¡œ ì„¸ë¡œ ë¹„ìœ¨ ì§€ì •\n",
    ")\n",
    "\n",
    "# ROI Pooling: ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ì˜ íŠ¹ì§•ë§µì—ì„œ RoI(Region of Interest)ë¥¼ ê³ ì • í¬ê¸°ë¡œ ë³€í™˜\n",
    "roi_pooler = ops.MultiScaleRoIAlign(\n",
    "    featmap_names=[\"0\"],         # ì‚¬ìš©í•  íŠ¹ì§•ë§µ ì´ë¦„\n",
    "    output_size=(7, 7),          # ì¶œë ¥ í¬ê¸° ì„¤ì • (7x7)\n",
    "    sampling_ratio=2             # ìƒ˜í”Œë§ ë¹„ìœ¨ ì§€ì •\n",
    ")\n",
    "\n",
    "# í•™ìŠµì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ë¥¼ ì„¤ì • (GPUê°€ ìžˆìœ¼ë©´ cuda, ì—†ìœ¼ë©´ cpu)\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Faster R-CNN ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# - backbone: íŠ¹ì§• ì¶”ì¶œê¸° (VGG16 ì‚¬ìš©)\n",
    "# - num_classes: ê²€ì¶œí•  í´ëž˜ìŠ¤ ìˆ˜ (ë°°ê²½ í¬í•¨; ì—¬ê¸°ì„œëŠ” 3ê°œë¡œ ì„¤ì •)\n",
    "# - rpn_anchor_generator: ìœ„ì—ì„œ ì„¤ì •í•œ ì•µì»¤ ìƒì„±ê¸°\n",
    "# - box_roi_pool: ìœ„ì—ì„œ ì„¤ì •í•œ ROI í’€ë§ ëª¨ë“ˆ\n",
    "model = FasterRCNN(\n",
    "    backbone=backbone,\n",
    "    num_classes=3, # ê°•ì•„ì§€, ê³ ì–‘ì´, ë°°ê²½\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ").to(device)  # ëª¨ë¸ì„ ì„ íƒí•œ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAFILE: /Library/Frameworks/Python.framework/Versions/3.13/etc/openssl/cert.pem\n",
      "HTTPS OK, status: 200\n"
     ]
    }
   ],
   "source": [
    "# %% ðŸ”Ž ì¸ì¦ì„œ ê²½ë¡œì™€ HTTPS ìš”ì²­ í…ŒìŠ¤íŠ¸\n",
    "import ssl, urllib.request\n",
    "try:\n",
    "    print(\"CAFILE:\", ssl.get_default_verify_paths().cafile)  # âœ… ê¸°ë³¸ ì¸ì¦ì„œ íŒŒì¼ ê²½ë¡œ\n",
    "    with urllib.request.urlopen(\"https://example.com\", timeout=5) as r:\n",
    "        print(\"HTTPS OK, status:\", r.status)                 # 200 ë‚˜ì˜¤ë©´ ì„±ê³µ\n",
    "except Exception as e:\n",
    "    print(\"âŒ ì˜¤ë¥˜:\", repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1758853234057,
     "user": {
      "displayName": "ì •ìˆ˜ë²”",
      "userId": "01425515440938538078"
     },
     "user_tz": -540
    },
    "id": "nEx9jRlm0MSA",
    "outputId": "2c56a568-78cd-469d-bc24-bef98d9a8210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(512, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(512, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=25088, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6l0fDBnf0n0s"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ìµœì í™” ê¸°ë²• ì„¤ì • (SGD ì‚¬ìš©)\n",
    "from torch import optim\n",
    "params = [p for p in model.parameters() if p.requires_grad]  # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë“¤ë§Œ ì„ íƒ\n",
    "optimizer = optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ì • ì—í­ë§ˆë‹¤ í•™ìŠµë¥  ê°ì†Œ\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Training:   6%|â–‹         | 38/607 [08:35<1:26:17,  9.10s/it, loss=nan]      "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„ (ì´ 5 ì—í­ ë™ì•ˆ í•™ìŠµ)\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # tqdm ì§„í–‰ë°”ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰ ìƒí™© í‘œì‹œ\n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "    for images, targets in train_bar:\n",
    "        # ì´ë¯¸ì§€ì™€ íƒ€ê²Ÿì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # ëª¨ë¸ì— ìž…ë ¥í•˜ì—¬ ì†ì‹¤(loss) ê³„ì‚°\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        losses.backward()      # ì—­ì „íŒŒ ìˆ˜í–‰\n",
    "        optimizer.step()       # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "\n",
    "        total_loss += losses.item()\n",
    "        train_bar.set_postfix(loss=f\"{losses.item():.3f}\")\n",
    "\n",
    "    lr_scheduler.step()  # ì—í­ì´ ëë‚œ í›„ í•™ìŠµë¥  ì—…ë°ì´íŠ¸\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch: {epoch+1:2d}, Avg Train Loss: {avg_train_loss:.3f}\")\n",
    "\n",
    "    # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” GPU ë©”ëª¨ë¦¬ í•´ì œ (ë©”ëª¨ë¦¬ ìµœì í™”)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNFzyyJ4AQYXVEueStGWLlg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
