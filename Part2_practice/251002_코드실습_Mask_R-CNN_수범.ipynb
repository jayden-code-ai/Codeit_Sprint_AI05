{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24209f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 51.2M  100 51.2M    0     0  2787k      0  0:00:18  0:00:18 --:--:-- 3386kk      0  0:00:20  0:00:13  0:00:07 2984k     0  0:00:19  0:00:16  0:00:03 3051k     0  0:00:18  0:00:18 --:--:-- 3310k\n",
      "Archive:  PennFudanPed.zip\n",
      "  inflating: PennFudanPed/added-object-list.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00001.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00002.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00003.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00004.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00005.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00006.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00007.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00008.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00009.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00010.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00011.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00012.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00013.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00014.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00015.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00016.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00017.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00018.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00019.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00020.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00021.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00022.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00023.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00024.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00025.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00026.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00027.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00028.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00029.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00030.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00031.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00032.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00033.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00034.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00035.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00036.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00037.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00038.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00039.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00040.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00041.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00042.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00043.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00044.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00045.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00046.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00047.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00048.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00049.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00050.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00051.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00052.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00053.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00054.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00055.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00056.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00057.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00058.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00059.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00060.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00061.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00062.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00063.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00064.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00065.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00066.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00067.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00068.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00069.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00070.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00071.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00072.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00073.txt  \n",
      "  inflating: PennFudanPed/Annotation/FudanPed00074.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00001.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00002.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00003.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00004.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00005.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00006.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00007.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00008.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00009.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00010.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00011.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00012.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00013.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00014.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00015.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00016.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00017.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00018.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00019.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00020.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00021.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00022.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00023.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00024.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00025.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00026.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00027.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00028.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00029.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00030.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00031.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00032.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00033.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00034.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00035.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00036.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00037.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00038.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00039.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00040.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00041.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00042.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00043.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00044.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00045.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00046.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00047.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00048.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00049.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00050.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00051.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00052.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00053.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00054.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00055.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00056.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00057.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00058.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00059.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00060.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00061.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00062.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00063.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00064.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00065.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00066.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00067.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00068.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00069.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00070.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00071.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00072.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00073.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00074.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00075.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00076.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00077.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00078.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00079.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00080.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00081.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00082.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00083.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00084.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00085.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00086.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00087.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00088.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00089.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00090.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00091.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00092.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00093.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00094.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00095.txt  \n",
      "  inflating: PennFudanPed/Annotation/PennPed00096.txt  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00001_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00002_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00003_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00004_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00005_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00006_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00007_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00008_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00009_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00010_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00011_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00012_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00013_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00014_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/FudanPed00015_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00016_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00017_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/FudanPed00018_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00019_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00020_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00021_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00022_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00023_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00024_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00025_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00026_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00027_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/FudanPed00028_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00029_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00030_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00031_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00032_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00033_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00034_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00035_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00036_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00037_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00038_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00039_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00040_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00041_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00042_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00043_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00044_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00045_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00046_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00047_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00048_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00049_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00050_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00051_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00052_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00053_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00054_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00055_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00056_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00057_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00058_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00059_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00060_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00061_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00062_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00063_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00064_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00065_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00066_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00067_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00068_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00069_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00070_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00071_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00072_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00073_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/FudanPed00074_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00001_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00002_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00003_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00004_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00005_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00006_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00007_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00008_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00009_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00010_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00011_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00012_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00013_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00014_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00015_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00016_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00017_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00018_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00019_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00020_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00021_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00022_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00023_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00024_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00025_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00026_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00027_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00028_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00029_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00030_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00031_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00032_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00033_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00034_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00035_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00036_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00037_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00038_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00039_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00040_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00041_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00042_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00043_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00044_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00045_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00046_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00047_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00048_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00049_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00050_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00051_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00052_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00053_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00054_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00055_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00056_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00057_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00058_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00059_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00060_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00061_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00062_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00063_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00064_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00065_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00066_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00067_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00068_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00069_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00070_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00071_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00072_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00073_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00074_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00075_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00076_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00077_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00078_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00079_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00080_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00081_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00082_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00083_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00084_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00085_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00086_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00087_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00088_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00089_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00090_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00091_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00092_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00093_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00094_mask.png  \n",
      "  inflating: PennFudanPed/PedMasks/PennPed00095_mask.png  \n",
      " extracting: PennFudanPed/PedMasks/PennPed00096_mask.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00001.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00002.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00003.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00004.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00005.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00006.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00007.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00008.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00009.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00010.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00011.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00012.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00013.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00014.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00015.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00016.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00017.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00018.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00019.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00020.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00021.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00022.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00023.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00024.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00025.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00026.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00027.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00028.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00029.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00030.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00031.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00032.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00033.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00034.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00035.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00036.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00037.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00038.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00039.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00040.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00041.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00042.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00043.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00044.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00045.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00046.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00047.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00048.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00049.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00050.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00051.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00052.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00053.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00054.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00055.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00056.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00057.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00058.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00059.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00060.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00061.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00062.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00063.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00064.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00065.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00066.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00067.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00068.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00069.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00070.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00071.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00072.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00073.png  \n",
      "  inflating: PennFudanPed/PNGImages/FudanPed00074.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00001.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00002.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00003.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00004.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00005.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00006.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00007.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00008.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00009.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00010.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00011.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00012.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00013.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00014.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00015.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00016.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00017.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00018.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00019.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00020.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00021.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00022.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00023.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00024.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00025.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00026.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00027.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00028.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00029.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00030.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00031.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00032.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00033.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00034.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00035.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00036.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00037.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00038.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00039.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00040.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00041.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00042.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00043.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00044.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00045.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00046.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00047.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00048.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00049.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00050.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00051.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00052.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00053.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00054.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00055.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00056.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00057.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00058.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00059.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00060.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00061.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00062.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00063.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00064.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00065.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00066.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00067.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00068.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00069.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00070.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00071.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00072.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00073.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00074.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00075.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00076.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00077.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00078.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00079.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00080.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00081.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00082.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00083.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00084.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00085.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00086.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00087.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00088.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00089.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00090.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00091.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00092.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00093.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00094.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00095.png  \n",
      "  inflating: PennFudanPed/PNGImages/PennPed00096.png  \n",
      "  inflating: PennFudanPed/readme.txt  \n"
     ]
    }
   ],
   "source": [
    "!curl -L https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip -o data/PennFudanPed.zip\n",
    "!cd data && unzip -o PennFudanPed.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed618fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "# 1. 데이터셋 정의 (PennFudanDataset)\n",
    "# PennFudan 데이터셋은 보행자 이미지와 각 이미지에 대한 마스크(분할 정보)를 포함합니다.\n",
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms):\n",
    "        \"\"\"\n",
    "        root: 데이터셋의 루트 폴더 (예: './PennFudanPed')\n",
    "        transforms: 이미지와 타겟에 적용할 변환 함수\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # PNGImages 폴더와 PedMasks 폴더 내의 파일 이름을 정렬해서 리스트로 저장\n",
    "        self.imgs = sorted(os.listdir(os.path.join(root, \"PNGImages\")))\n",
    "        self.masks = sorted(os.listdir(os.path.join(root, \"PedMasks\")))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx번째 이미지와 마스크의 파일 경로 생성\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "\n",
    "        # read_image: 이미지를 Tensor 형식으로 읽어옵니다.\n",
    "        img = read_image(img_path)\n",
    "        mask = read_image(mask_path)\n",
    "\n",
    "        # mask 텐서의 유니크한 값(색상 또는 인스턴스 번호)을 추출합니다.\n",
    "        # 첫 번째 값은 배경이므로 제거합니다.\n",
    "        obj_ids = torch.unique(mask)[1:]\n",
    "\n",
    "        # 각 객체 인스턴스에 대해 binary mask를 생성합니다.\n",
    "        # mask == obj_ids[:, None, None]는 각 인스턴스마다 True/False 마스크를 만듭니다.\n",
    "        # .to(dtype=torch.uint8)로 자료형을 8비트 정수형으로 변환합니다.\n",
    "        masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
    "\n",
    "        # masks_to_boxes: 각 binary mask에서 바운딩 박스([x_min, y_min, x_max, y_max]) 계산\n",
    "        boxes = masks_to_boxes(masks)\n",
    "\n",
    "        # PennFudan 데이터셋은 보행자만 있으므로, 모든 객체에 1번 라벨을 부여합니다.\n",
    "        labels = torch.ones((len(obj_ids),), dtype=torch.int64)\n",
    "\n",
    "        # 이미지 id는 단순히 idx 값을 사용 (평가 시 사용)\n",
    "        image_id = idx\n",
    "\n",
    "        # 각 바운딩 박스의 면적 계산: (x_max - x_min) * (y_max - y_min)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # 모든 객체는 군집(crowd)이 아니라고 가정하여 0으로 설정합니다.\n",
    "        iscrowd = torch.zeros((len(obj_ids),), dtype=torch.int64)\n",
    "\n",
    "        # tv_tensors를 사용하여 이미지와 타겟을 래핑합니다.\n",
    "        # 이는 torchvision의 최신 변환 및 시각화 기능을 사용하기 위함입니다.\n",
    "        img = tv_tensors.Image(img)\n",
    "        target = {\n",
    "            \"boxes\": tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img)),\n",
    "            \"masks\": tv_tensors.Mask(masks),\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd\n",
    "        }\n",
    "\n",
    "        # 만약 변환(transforms)이 있다면 적용 (예: 데이터 증강)\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 전체 이미지 수 반환\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49269233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 변환 함수 정의\n",
    "\n",
    "def get_transform(train):\n",
    "    transform = []\n",
    "    if train:\n",
    "        transform.append(T.RandomHorizontalFlip())\n",
    "        transform.append(T.RandomRotation(degrees=(-20, 20)))\n",
    "    transform.append(T.ToDtype(torch.float, scale=True))\n",
    "    transform.append(T.ToPureTensor())\n",
    "    return T.Compose(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8984868",
   "metadata": {},
   "source": [
    "현재 `torchvision.models.detection.maskrcnn_resnet50_fpn` 모델은 COCO 데이터셋으로 학습되어 있으나, `PennFudanDataset`은 배경과 객체만 구분하므로 모델을 수정해주어야 합니다.\n",
    "\n",
    "1. **COCO 데이터셋과 클래스 수 차이**  \n",
    "   - COCO 데이터셋은 약 91개의 객체 클래스로 학습되어 있습니다.  \n",
    "   - 여러분의 데이터셋(예제에서는 PennFudan)에서는 보통 배경(0)과 실제 객체(예: 보행자만 있다면 1) 또는 다른 소수의 클래스를 사용합니다.  \n",
    "   - 따라서, 기존의 분류기(head)는 COCO의 클래스 수에 맞게 설계되어 있으므로, 여러분의 데이터셋에 맞게 새롭게 구성할 필요가 있습니다.\n",
    "\n",
    "2. **박스 예측기(Box Predictor) 교체**  \n",
    "   - 모델의 `roi_heads.box_predictor`는 객체의 바운딩 박스를 예측하고, 객체 클래스에 대한 점수를 산출합니다.  \n",
    "   - 이 계층은 COCO에 맞게 학습되어 있기 때문에, 여러분의 데이터셋에 맞는 클래스 수(예: 3개: 배경 + 2개 클래스)로 출력 차원을 변경해야 합니다.  \n",
    "   - `FastRCNNPredictor`를 사용하여 새롭게 구성함으로써, 입력 피처 수는 그대로 사용하지만 최종 출력 뉴런의 수가 `num_classes`에 맞게 설정됩니다.\n",
    "\n",
    "3. **마스크 예측기(Mask Predictor) 교체**  \n",
    "   - Mask R-CNN은 각 객체의 분할 마스크도 예측하는데, 이때 사용되는 `roi_heads.mask_predictor` 역시 COCO용으로 설계되어 있습니다.  \n",
    "   - 여러분의 데이터셋에서 사용되는 클래스 수에 맞게 마스크 예측기의 출력 채널을 변경해야 합니다.  \n",
    "   - `MaskRCNNPredictor`를 사용하여 새롭게 구성하면, 마찬가지로 입력 채널 수는 그대로 유지하면서 최종 출력이 여러분이 원하는 클래스 수에 맞게 조정됩니다.\n",
    "\n",
    "4. **모델 파인튜닝의 목적**  \n",
    "   - 사전 학습된 모델의 대부분의 레이어(특히, 백본과 FPN)는 일반적인 특징 추출에 강력하기 때문에 그대로 사용합니다.  \n",
    "   - 하지만, 마지막에 위치한 분류기와 마스크 예측기는 데이터셋마다 클래스 수가 다르므로 반드시 교체해 주어야 합니다.\n",
    "   - 이렇게 하면 사전 학습된 가중치를 활용하면서도, 여러분의 특정 데이터셋에 최적화된 결과를 얻을 수 있습니다.\n",
    "\n",
    "요약하면,  \n",
    "- **분류기와 마스크 예측기를 교체하는 이유는**: 기존 모델이 COCO 데이터셋에 맞춰 학습되었기 때문에 출력 클래스 수가 여러분의 데이터셋과 다르기 때문입니다.  \n",
    "- **FastRCNNPredictor와 MaskRCNNPredictor를 사용하는 이유는**: 기존의 마지막 계층을 여러분의 클래스 수에 맞춰 재구성하여, 사전 학습된 모델의 강점을 그대로 활용하면서도 올바른 출력을 얻기 위함입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fffd18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 정의 (COCO 사전 학습된 Mask R-CNN 사용)\n",
    "\n",
    "# COCO에서 사전 학습된 Mask R-CNN (ResNet50 FPN 기반) 모델을 사용하여 파인튜닝합니다.\n",
    "# 이 모델은 객체 검출 및 인스턴스 분할을 모두 수행합니다.\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "\n",
    "device = 'mps' if torch.mps.is_available() else 'cpu'\n",
    "\n",
    "# torchvision에서 COCO 데이터셋으로 사전 학습된 Mask R-CNN 모델 불러오기\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e16cd782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
      "    )\n",
      "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
      "    (mask_head): MaskRCNNHeads(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_predictor): MaskRCNNPredictor(\n",
      "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e307300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 박스 예측기 (classification head) 교체\n",
    "# -------------------------\n",
    "# 모델의 마지막 계층인 box_predictor의 입력 피처 수를 확인합니다.\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# FastRCNNPredictor를 사용하여 새롭게 분류기(head)를 생성합니다.\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b83d525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 마스크 예측기 (mask head) 교체\n",
    "# -------------------------\n",
    "# mask_predictor의 conv5_mask 레이어의 입력 채널 수 확인\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256  # 마스크 예측기에서 사용할 숨겨진 레이어의 크기\n",
    "# MaskRCNNPredictor를 사용하여 마스크 분류기(head)를 새롭게 생성합니다.\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "\n",
    "# 모델을 선택한 디바이스(CPU 또는 GPU)로 이동\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f44a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DataLoader 및 collate_fn 정의\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    DataLoader에서 배치를 생성할 때, 각 이미지와 타겟을 하나의 튜플로 묶어줍니다.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# 데이터셋 준비: PennFudan 데이터셋의 경로와 변환 함수 지정\n",
    "dataset = PennFudanDataset('/Users/jayden/Projects/my-first-py/data/PennFudanPed', get_transform(train=True))\n",
    "dataset_test = PennFudanDataset('/Users/jayden/Projects/my-first-py/data/PennFudanPed', get_transform(train=False))\n",
    "\n",
    "# 데이터셋을 학습용과 테스트용으로 나눕니다.\n",
    "# 여기서는 무작위로 선택하여 마지막 50개 이미지를 테스트셋으로 사용합니다.\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# DataLoader 생성: 배치 크기, 셔플 여부, 그리고 collate_fn 지정\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6edee3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tImpacting Interactivity (0000000e:kIOGPUCommandBufferCallbackErrorImpactingInteractivity)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0xb42002680>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0xaf6064000>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x103365d60>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0xaf6064000>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tImpacting Interactivity (0000000e:kIOGPUCommandBufferCallbackErrorImpactingInteractivity)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0xb42002d80>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0xaf6064000>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x103365d60>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0xaf6064000>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m targets = [{k: (v.to(device) \u001b[38;5;28;01mif\u001b[39;00m torch.is_tensor(v) \u001b[38;5;28;01melse\u001b[39;00m v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t.items()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 모델에 이미지와 타겟을 전달하면, 학습 모드에서는 손실(loss) dict를 반환합니다.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m loss_dict = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# dict의 모든 손실값을 합산하여 총 손실을 계산합니다.\u001b[39;00m\n\u001b[32m     21\u001b[39m losses = \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torchvision/models/detection/generalized_rcnn.py:117\u001b[39m, in \u001b[36mGeneralizedRCNN.forward\u001b[39m\u001b[34m(self, images, targets)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch.Tensor):\n\u001b[32m    116\u001b[39m     features = OrderedDict([(\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m, features)])\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m proposals, proposal_losses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrpn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m detections, detector_losses = \u001b[38;5;28mself\u001b[39m.roi_heads(features, proposals, images.image_sizes, targets)\n\u001b[32m    119\u001b[39m detections = \u001b[38;5;28mself\u001b[39m.transform.postprocess(\n\u001b[32m    120\u001b[39m     detections, images.image_sizes, original_image_sizes\n\u001b[32m    121\u001b[39m )  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torchvision/models/detection/rpn.py:380\u001b[39m, in \u001b[36mRegionProposalNetwork.forward\u001b[39m\u001b[34m(self, images, features, targets)\u001b[39m\n\u001b[32m    378\u001b[39m     labels, matched_gt_boxes = \u001b[38;5;28mself\u001b[39m.assign_targets_to_anchors(anchors, targets)\n\u001b[32m    379\u001b[39m     regression_targets = \u001b[38;5;28mself\u001b[39m.box_coder.encode(matched_gt_boxes, anchors)\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m     loss_objectness, loss_rpn_box_reg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobjectness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_bbox_deltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregression_targets\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     losses = {\n\u001b[32m    384\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloss_objectness\u001b[39m\u001b[33m\"\u001b[39m: loss_objectness,\n\u001b[32m    385\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloss_rpn_box_reg\u001b[39m\u001b[33m\"\u001b[39m: loss_rpn_box_reg,\n\u001b[32m    386\u001b[39m     }\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m boxes, losses\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/my-first-py/.venv/lib/python3.13/site-packages/torchvision/models/detection/rpn.py:315\u001b[39m, in \u001b[36mRegionProposalNetwork.compute_loss\u001b[39m\u001b[34m(self, objectness, pred_bbox_deltas, labels, regression_targets)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03m    objectness (Tensor)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m \u001b[33;03m    box_loss (Tensor)\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    314\u001b[39m sampled_pos_inds, sampled_neg_inds = \u001b[38;5;28mself\u001b[39m.fg_bg_sampler(labels)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m sampled_pos_inds = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_pos_inds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    316\u001b[39m sampled_neg_inds = torch.where(torch.cat(sampled_neg_inds, dim=\u001b[32m0\u001b[39m))[\u001b[32m0\u001b[39m]\n\u001b[32m    318\u001b[39m sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 5. 간단한 학습 루프 (2 에폭 예시)\n",
    "# 학습 가능한 파라미터만 모아 옵티마이저에 전달\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# 학습률 스케줄러: 3 에폭마다 학습률을 0.1배 감소\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "num_epochs = 2  # 학습 에폭 수\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 전환 (Dropout, BatchNorm 등이 학습 모드로 작동)\n",
    "    epoch_loss = 0  # 에폭별 손실 누적 변수\n",
    "    for images, targets in data_loader:\n",
    "        # 각 이미지와 타겟을 device(GPU 또는 CPU)로 이동\n",
    "        images = [img.to(device) for img in images]\n",
    "        # 타겟은 dict 형식이며, tensor인 항목만 to(device) 처리\n",
    "        targets = [{k: (v.to(device) if torch.is_tensor(v) else v) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # 모델에 이미지와 타겟을 전달하면, 학습 모드에서는 손실(loss) dict를 반환합니다.\n",
    "        loss_dict = model(images, targets)\n",
    "        # dict의 모든 손실값을 합산하여 총 손실을 계산합니다.\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()  # 손실 값을 float로 누적\n",
    "\n",
    "        optimizer.zero_grad()  # 이전 배치의 기울기(gradient) 초기화\n",
    "        losses.backward()      # 역전파를 통해 기울기 계산\n",
    "        optimizer.step()       # 옵티마이저가 파라미터를 업데이트\n",
    "\n",
    "    lr_scheduler.step()  # 에폭마다 학습률 업데이트\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022d000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
