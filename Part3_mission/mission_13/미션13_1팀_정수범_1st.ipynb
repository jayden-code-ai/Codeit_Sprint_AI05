{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mission 13: 쇼핑몰 리뷰 감성 분석 (PEFT)\n",
                "\n",
                "> **[중요] CUDA Error 발생 시 해결 방법**\n",
                ">\n",
                "> 만약 학습 도중 `CUDA error: device-side assert triggered` 오류가 발생한다면, 이는 주로 **라벨링 문제** 때문입니다.\n",
                "> 이 오류는 한 번 발생하면 커널(Kernel) 상태가 꼬여서 코드를 수정해도 계속 같은 오류가 뜹니다.\n",
                "> **반드시 상단 메뉴의 [Kernel] -> [Restart Kernel]을 눌러 커널을 재시작한 후 처음부터 다시 실행해주세요.**\n",
                "\n",
                "## 1. 미션 소개\n",
                "쇼핑몰 리뷰 데이터를 활용하여 감성(긍정/부정)을 분석하는 모델을 개발하는 미션입니다.\n",
                "단순히 모델을 학습시키는 것을 넘어, **Full Fine-Tuning** 방식과 **PEFT (Parameter-Efficient Fine-Tuning)** 두 가지 방식을 모두 적용해보고, 그 효율성과 성능을 비교 분석하는 것이 핵심 목표입니다.\n",
                "\n",
                "## 2. 미션 목표\n",
                "1. **데이터 전처리**: Raw Json 데이터에서 텍스트와 라벨을 추출하고 학습 가능한 형태로 변환\n",
                "2. **모델 학습 (2가지 방식)**:\n",
                "    - **Full Fine-Tuning**: 모델의 모든 파라미터를 업데이트\n",
                "    - **PEFT (LoRA 등)**: 일부 파라미터만 효율적으로 업데이트\n",
                "3. **성능 및 효율성 비교**:\n",
                "    - 학습 속도, 메모리 사용량, 모델 용량 비교\n",
                "    - 정확도(Accuracy) 등 감성 분석 성능 비교\n",
                "4. **결과 정리**: 코드와 마크다운을 통해 전체 프로세스와 결과 분석을 체계적으로 정리\n",
                "\n",
                "## 3. 데이터 소개\n",
                "- **데이터셋 경로**: `/mnt/nas/jayden_code/Codeit_Practice/Part3_mission_13/review-sentiment-analysis`\n",
                "- **구조**:\n",
                "    - 대분류: SNS / 쇼핑몰\n",
                "    - 중분류: 패션, 화장품, 가전, IT기기, 생활\n",
                "    - 소분류: (예: 여성의류, 남성의류 등)\n",
                "    - 파일 형식: JSON\n",
                "- **핵심 필드**:\n",
                "    - `RawText`: 리뷰 텍스트 본문\n",
                "    - `GeneralPolarity`: 감성 라벨 (-1: 부정, 0: 중립, 1: 긍정)\n",
                "\n",
                "## 4. 데이터 분석 (EDA) 및 전처리 계획\n",
                "1. **탐색적 데이터 분석 (EDA)**:\n",
                "    - 카테고리별 데이터 분포 확인\n",
                "    - 라벨(긍정/부정/중립) 불균형 확인\n",
                "    - 리뷰 텍스트 길이 분포 분석\n",
                "2. **전처리 (Preprocessing)**:\n",
                "    - **라벨링 변환**: -1(부정), 0(중립), 1(긍정) -> 모델 학습용 클래스 (0, 1, 2)로 매핑\n",
                "    - **데이터 통합**: 여러 JSON 파일을 pandas DataFrame으로 통합\n",
                "    - **Train/Test 분리**: 학습 및 평가를 위한 데이터셋 분할 (예: 8:2)\n",
                "    - **토크나이징**: Pre-trained 모델의 Tokenizer 적용\n",
                "\n",
                "## 5. 진행 계획 (가이드라인 준수)\n",
                "1. **기초 작업**: 데이터 탐색 및 Dataset 클래스 생성\n",
                "2. **베이스라인 설정**: Hugging Face `transformers` 라이브러리의 Pre-trained 모델 선택 (예: `klue/roberta-base` or `beomi/KcELECTRA-base`)\n",
                "3. **Full Fine-Tuning 구현**:\n",
                "    - `Trainer` API 활용\n",
                "    - 전체 파라미터 학습\n",
                "    - 평가 지표(Accuracy, F1) 확인\n",
                "4. **PEFT (LoRA) 구현**:\n",
                "    - `peft` 라이브러리 활용\n",
                "    - LoRA Config 설정 (rank, alpha 등)\n",
                "    - 학습 진행 및 저장\n",
                "5. **비교 및 리포트**:\n",
                "    - 학습 시간, 저장 용량, 추론 성능 비교 테이블 작성\n",
                "    - 결론 도출\n",
                "\n",
                "---\n",
                "*초보자 친화적인 코드로, 각 단계별로 주석을 상세히 달아 진행하겠습니다.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 라이브러리 임포트\n",
                "데이터 분석과 모델 학습에 필요한 라이브러리들을 불러옵니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "라이브러리 로드 완료!\n"
                    ]
                }
            ],
            "source": [
                "# 필요한 라이브러리들을 불러옵니다.\n",
                "# os: 파일 경로 탐색을 위해 사용\n",
                "# json: JSON 형식의 데이터 파일을 읽기 위해 사용\n",
                "# pandas: 데이터를 표 형태로 다루기 위해 사용 (엑셀과 비슷하다고 생각하시면 됩니다!)\n",
                "# numpy: 수치 계산을 위해 사용\n",
                "import os\n",
                "import json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Hugging Face 라이브러리 (데이터셋 및 모델 관련)\n",
                "from datasets import Dataset\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, f1_score # 평가 지표\n",
                "\n",
                "print(\"라이브러리 로드 완료!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 데이터 로드 함수 정의\n",
                "여러 폴더에 흩어져 있는 JSON 파일들을 재귀적으로 탐색하여 하나의 리스트로 모으는 함수입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "데이터 로드를 시작합니다... (시간이 조금 걸릴 수 있어요)\n",
                        "총 184525개의 리뷰 데이터를 불러왔습니다!\n"
                    ]
                }
            ],
            "source": [
                "# 1. 데이터 로드 및 전처리 시작\n",
                "\n",
                "# 데이터가 저장된 원본 경로입니다.\n",
                "DATA_DIR = \"/mnt/nas/jayden_code/Codeit_Practice/Part3_mission_13/review-sentiment-analysis\"\n",
                "\n",
                "# 모든 폴더를 돌면서 JSON 파일을 찾아 데이터를 모으는 함수를 만듭니다.\n",
                "def load_data(root_dir):\n",
                "    \"\"\"\n",
                "    지정된 경로(root_dir) 하위의 모든 폴더를 탐색하여 JSON 파일을 읽고,\n",
                "    리뷰 텍스트(RawText)와 감성 라벨(GeneralPolarity)을 추출하여 리스트로 반환합니다.\n",
                "    \"\"\"\n",
                "    all_data = [] # 데이터를 모을 빈 리스트 생성\n",
                "    \n",
                "    print(\"데이터 로드를 시작합니다... (시간이 조금 걸릴 수 있어요)\")\n",
                "    \n",
                "    # os.walk를 사용하여 root_dir 하위의 모든 파일 경로를 방문합니다.\n",
                "    for root, dirs, files in os.walk(root_dir):\n",
                "        for file in files:\n",
                "            if file.endswith(\".json\"): # 파일 이름이 .json으로 끝나는 경우만 처리\n",
                "                file_path = os.path.join(root, file)\n",
                "                \n",
                "                try:\n",
                "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
                "                        data = json.load(f)\n",
                "                        \n",
                "                        # JSON 구조 확인: 보통 'data' 리스트 안에 개별 리뷰가 들어있거나, \n",
                "                        # 파일 구조에 따라 다를 수 있으므로 리스트 형태인지 확인합니다.\n",
                "                        # 데이터셋 명세를 보면 하나 혹은 여러개의 리뷰가 들어있을 수 있습니다.\n",
                "                        \n",
                "                        # 만약 data가 리스트라면 여러 리뷰가 들어있는 것입니다.\n",
                "                        if isinstance(data, list):\n",
                "                            for item in data:\n",
                "                                # 필요한 데이터만 쏙쏙 뽑아냅니다.\n",
                "                                if 'RawText' in item and 'GeneralPolarity' in item:\n",
                "                                    text = item['RawText'] # 리뷰 텍스트\n",
                "                                    # ★ 중요 수정: JSON의 라벨값이 문자열(\"1\", \"-1\")로 되어있을 수 있으므로 int로 변환해줍니다.\n",
                "                                    label = int(item['GeneralPolarity']) \n",
                "                                    \n",
                "                                    # ★ 안전 장치: 라벨이 -1, 0, 1이 아닌 이상한 값이면 제외합니다.\n",
                "                                    if label not in [-1, 0, 1]:\n",
                "                                        continue\n",
                "\n",
                "                                    # 리스트에 추가 (딕셔너리 형태)\n",
                "                                    all_data.append({\n",
                "                                        'text': text,\n",
                "                                        'label': label\n",
                "                                    })\n",
                "                        # 만약 딕셔너리라면 하나의 객체일 수도 있습니다 (구조에 따라 다름, 일단 리스트라 가정하고 진행)\n",
                "                        elif isinstance(data, dict):\n",
                "                             # 혹시 data 자체가 하나의 리뷰 뭉치일 수도 있으니 구조에 맞춰 처리\n",
                "                             # (실제 데이터 형태를 보고 수정이 필요할 수도 있습니다. 우선 일반적인 경우를 상정합니다)\n",
                "                             if 'RawText' in data and 'GeneralPolarity' in data:\n",
                "                                 label = int(data['GeneralPolarity'])\n",
                "                                 if label not in [-1, 0, 1]:\n",
                "                                     continue\n",
                "\n",
                "                                 all_data.append({\n",
                "                                     'text': data['RawText'],\n",
                "                                     'label': label\n",
                "                                 })\n",
                "                                 \n",
                "                except Exception as e:\n",
                "                    print(f\"파일 읽기 오류 발생 ({file}): {e}\")\n",
                "                    continue\n",
                "                    \n",
                "    print(f\"총 {len(all_data)}개의 리뷰 데이터를 불러왔습니다!\")\n",
                "    return all_data\n",
                "\n",
                "# 함수 실행!\n",
                "raw_data = load_data(DATA_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 데이터 확인 (DataFrame 변환)\n",
                "로드한 데이터를 Pandas DataFrame으로 변환하고, 데이터의 구조와 라벨 분포를 확인합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "데이터 미리보기:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>text</th>\n",
                            "      <th>label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>이것저것 바르기를 워낙 싫어하는 남편한테 최고의 제품이네요. 하나만 바르니 사용하기...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>향은 남성 화장품 냄새가 좀 강해서 아쉽고 유통기한은 내년 3월까지라 무지 짧네요.</td>\n",
                            "      <td>-1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>가격 저렴하고 배송 빠르고 용량도 엄청나고 향도 나쁘지 않아요. 잘산 것 같아요.</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1+1행사로 남편 선물했는데 향도 괜찮고 조금만 발라도 잘 발라진다고 좋은 거 같다...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>향이 강하지 않고 깔끔한 느낌의 향이에요. 배송도 빨라서 좋았습니다. 다만 끈적임이...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                text  label\n",
                            "0  이것저것 바르기를 워낙 싫어하는 남편한테 최고의 제품이네요. 하나만 바르니 사용하기...      1\n",
                            "1     향은 남성 화장품 냄새가 좀 강해서 아쉽고 유통기한은 내년 3월까지라 무지 짧네요.     -1\n",
                            "2      가격 저렴하고 배송 빠르고 용량도 엄청나고 향도 나쁘지 않아요. 잘산 것 같아요.      1\n",
                            "3  1+1행사로 남편 선물했는데 향도 괜찮고 조금만 발라도 잘 발라진다고 좋은 거 같다...      1\n",
                            "4  향이 강하지 않고 깔끔한 느낌의 향이에요. 배송도 빨라서 좋았습니다. 다만 끈적임이...      0"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "데이터 정보:\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 184525 entries, 0 to 184524\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column  Non-Null Count   Dtype \n",
                        "---  ------  --------------   ----- \n",
                        " 0   text    184525 non-null  object\n",
                        " 1   label   184525 non-null  int64 \n",
                        "dtypes: int64(1), object(1)\n",
                        "memory usage: 2.8+ MB\n",
                        "None\n",
                        "\n",
                        "라벨 분포 확인:\n",
                        "label\n",
                        " 1    118870\n",
                        " 0     37592\n",
                        "-1     28063\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# 모은 데이터를 보기 편하게 pandas DataFrame으로 변환합니다.\n",
                "df = pd.DataFrame(raw_data)\n",
                "\n",
                "# 상위 5개 데이터를 눈으로 확인해봅니다.\n",
                "print(\"데이터 미리보기:\")\n",
                "display(df.head())\n",
                "\n",
                "# 데이터 정보 확인 (빈 값이 있는지, 데이터 타입은 무엇인지)\n",
                "print(\"\\n데이터 정보:\")\n",
                "print(df.info())\n",
                "\n",
                "# 라벨 분포 확인 (긍정, 부정, 중립 개수 확인)\n",
                "# -1: 부정, 0: 중립, 1: 긍정\n",
                "print(\"\\n라벨 분포 확인:\")\n",
                "print(df['label'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 라벨 인코딩 (전처리)\n",
                "모델 학습을 위해 라벨을 0부터 시작하는 정수형(0, 1, 2)으로 변환합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "현재 라벨 종류: {np.int64(0), np.int64(1), np.int64(-1)}\n",
                        "라벨 변환을 수행합니다...\n",
                        "라벨 변환 결과 확인:\n",
                        "0    2\n",
                        "1    0\n",
                        "2    2\n",
                        "3    2\n",
                        "4    1\n",
                        "Name: label, dtype: int64\n",
                        "\n",
                        "변환된 라벨 분포:\n",
                        "label\n",
                        "2    118870\n",
                        "1     37592\n",
                        "0     28063\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# 라벨을 모델이 학습하기 편한 숫자(0, 1, 2)로 바꿔줍니다.\n",
                "# Hugging Face 모델들은 보통 0부터 시작하는 정수 레이블을 기대합니다.\n",
                "# -1 -> 0 (부정)\n",
                "#  0 -> 1 (중립)\n",
                "#  1 -> 2 (긍정)\n",
                "\n",
                "label_map = {-1: 0, 0: 1, 1: 2}\n",
                "\n",
                "# ★ 안전 장치: 이미 변환된 경우(0, 1, 2만 있는 경우)에는 다시 변환하지 않도록 체크합니다.\n",
                "unique_labels = set(df['label'].unique())\n",
                "print(f\"현재 라벨 종류: {unique_labels}\")\n",
                "\n",
                "# 만약 -1이 포함되어 있다면 변환을 수행합니다.\n",
                "if -1 in unique_labels:\n",
                "    print(\"라벨 변환을 수행합니다...\")\n",
                "    df['label'] = df['label'].map(label_map)\n",
                "else:\n",
                "    print(\"이미 라벨이 변환되어 있거나, 변환할 필요가 없습니다.\")\n",
                "\n",
                "# 잘 바뀌었는지 확인\n",
                "print(\"라벨 변환 결과 확인:\")\n",
                "print(df['label'].head())\n",
                "\n",
                "# 변환된 라벨 분포도 다시 한 번 확인\n",
                "print(\"\\n변환된 라벨 분포:\")\n",
                "print(df['label'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 학습/테스트 데이터 분할\n",
                "전체 데이터를 학습용(Train)과 테스트용(Test)으로 8:2 비율로 나눕니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "학습 데이터 개수: 147620\n",
                        "테스트 데이터 개수: 36905\n",
                        "\n",
                        "변환된 데이터셋 확인:\n",
                        "Dataset({\n",
                        "    features: ['text', 'label', '__index_level_0__'],\n",
                        "    num_rows: 147620\n",
                        "})\n",
                        "\n",
                        "[최종 점검] 학습 데이터셋 라벨 종류: {0, 1, 2}\n"
                    ]
                }
            ],
            "source": [
                "# 전체 데이터를 학습용(Train)과 테스트용(Test)으로 나눕니다.\n",
                "# test_size=0.2 의미는 전체의 20%를 테스트용으로 쓰겠다는 뜻입니다.\n",
                "# random_state=42는 매번 실행할 때마다 똑같이 나누기 위해 설정하는 난수 시드값입니다.\n",
                "# stratify 옵션을 사용하면 라벨 비율을 유지하면서 나눌 수 있습니다.\n",
                "\n",
                "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
                "\n",
                "print(f\"학습 데이터 개수: {len(train_df)}\")\n",
                "print(f\"테스트 데이터 개수: {len(test_df)}\")\n",
                "\n",
                "# Hugging Face의 Dataset 형식으로 변환합니다.\n",
                "# 이렇게 변환하면 transformers 라이브러리에서 다루기 훨씬 편해집니다.\n",
                "train_dataset = Dataset.from_pandas(train_df)\n",
                "test_dataset = Dataset.from_pandas(test_df)\n",
                "\n",
                "print(\"\\n변환된 데이터셋 확인:\")\n",
                "print(train_dataset)\n",
                "\n",
                "# ★ 최종 점검: 학습 데이터셋의 라벨이 정말 0, 1, 2인지 확인합니다.\n",
                "print(\"\\n[최종 점검] 학습 데이터셋 라벨 종류:\", set(train_dataset['label']))\n",
                "assert set(train_dataset['label']).issubset({0, 1, 2}), \"라벨에 0, 1, 2 이외의 값이 포함되어 있습니다!\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 토크나이저 로드\n",
                "Pre-trained 모델(KLUE RoBERTa)의 토크나이저를 불러옵니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "klue/roberta-base 모델의 토크나이저를 로드합니다...\n",
                        "원본 문장: 이 쇼핑몰 배송이 정말 빠르네요!\n",
                        "토큰화 결과 (Input IDs): [0, 1504, 7576, 9488, 2052, 3944, 5185, 2203, 2182, 5, 2]\n",
                        "토큰 복원 결과: [CLS] 이 쇼핑몰 배송이 정말 빠르네요! [SEP]\n"
                    ]
                }
            ],
            "source": [
                "# Hugging Face Hub에서 미리 학습된 모델의 토크나이저를 불러옵니다.\n",
                "# 한국어 모델 성능이 좋은 KLUE RoBERTa 모델을 사용하겠습니다.\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "model_id = \"klue/roberta-base\"\n",
                "print(f\"{model_id} 모델의 토크나이저를 로드합니다...\")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
                "\n",
                "# 토크나이저가 잘 작동하는지 테스트해봅시다.\n",
                "sample_text = \"이 쇼핑몰 배송이 정말 빠르네요!\"\n",
                "tokens = tokenizer(sample_text)\n",
                "print(f\"원본 문장: {sample_text}\")\n",
                "print(f\"토큰화 결과 (Input IDs): {tokens['input_ids']}\")\n",
                "print(f\"토큰 복원 결과: {tokenizer.decode(tokens['input_ids'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 데이터 토큰화\n",
                "전체 데이터셋을 토크나이저를 이용해 모델이 이해할 수 있는 형태로 변환합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "토크나이징 진행 중... (데이터가 많으면 조금 걸릴 수 있습니다)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "df0dfc26bdd4441f94af7290ca3a2b2e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/147620 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7b572be916ff42e7935dbe78f4ea6755",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/36905 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "토크나이징 완료!\n",
                        "Dataset({\n",
                        "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "    num_rows: 147620\n",
                        "})\n"
                    ]
                }
            ],
            "source": [
                "# 전체 데이터셋에 토크나이저를 적용하는 함수를 만듭니다.\n",
                "def preprocess_function(examples):\n",
                "    # 'text' 컬럼의 문장들을 토크나이저에 넣습니다.\n",
                "    # truncation=True: 문장이 너무 길면 모델이 처리할 수 있는 최대 길이(보통 512, 여기선 128로 제한)로 자릅니다.\n",
                "    # (학습 속도와 메모리를 위해 길이를 128 정도로 제한해보겠습니다)\n",
                "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
                "\n",
                "# map 함수를 사용하여 전체 데이터셋에 적용합니다.\n",
                "# batched=True를 하면 여러 문장을 한 번에 처리해서 속도가 빨라집니다.\n",
                "print(\"토크나이징 진행 중... (데이터가 많으면 조금 걸릴 수 있습니다)\")\n",
                "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
                "tokenized_test = test_dataset.map(preprocess_function, batched=True)\n",
                "\n",
                "print(\"토크나이징 완료!\")\n",
                "print(tokenized_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Full Fine-Tuning 모델 학습\n",
                "모델의 모든 파라미터를 업데이트하는 Full Fine-Tuning 방식을 수행합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
                        "/tmp/ipykernel_2741255/1771491142.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
                        "  trainer_full = Trainer(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Full Fine-Tuning 학습 시작...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='9227' max='9227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [9227/9227 47:26, Epoch 1/1]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "      <th>F1</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.233800</td>\n",
                            "      <td>0.224464</td>\n",
                            "      <td>0.911042</td>\n",
                            "      <td>0.878896</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Full Fine-Tuning 학습 및 저장 완료!\n"
                    ]
                }
            ],
            "source": [
                "# ==========================================\n",
                "# 2. Full Fine-Tuning 모델 학습\n",
                "# ==========================================\n",
                "\n",
                "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
                "\n",
                "# 평가 지표를 계산하는 함수입니다.\n",
                "def compute_metrics(pred):\n",
                "    labels = pred.label_ids\n",
                "    preds = pred.predictions.argmax(-1)\n",
                "    \n",
                "    acc = accuracy_score(labels, preds)\n",
                "    f1 = f1_score(labels, preds, average='macro') # 3개 클래스이므로 macro 평균\n",
                "    \n",
                "    return {\n",
                "        'accuracy': acc,\n",
                "        'f1': f1\n",
                "    }\n",
                "\n",
                "# 모델 로드 (라벨 개수는 3개: 부정, 중립, 긍정)\n",
                "model_full = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=3)\n",
                "\n",
                "# 학습을 위한 설정값들입니다.\n",
                "# output_dir: 결과가 저장될 폴더\n",
                "# num_train_epochs: 데이터셋을 몇 번 반복해서 학습할지 \n",
                "# learning_rate: 학습률 (얼마나 세밀하게 학습할지)\n",
                "full_finetuning_args = TrainingArguments(\n",
                "    output_dir=\"./saved_models/full_finetune\",\n",
                "    eval_strategy=\"epoch\", # [수정] evaluation_strategy -> eval_strategy\n",
                "    save_strategy=\"epoch\", # 매 에포크마다 모델 저장\n",
                "    learning_rate=2e-5, \n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=16,\n",
                "    num_train_epochs=1, # 빠른 실습을 위해 1 epoch만 설정 (성능을 높이려면 3정도로 늘려주세요)\n",
                "    weight_decay=0.01,\n",
                "    load_best_model_at_end=True, # 학습이 끝나면 가장 성능 좋은 모델을 불러옴\n",
                "    metric_for_best_model=\"accuracy\",\n",
                "    save_total_limit=1 # 용량 절약을 위해 가장 좋은 모델 1개만 저장\n",
                ")\n",
                "\n",
                "# Trainer 객체 생성\n",
                "trainer_full = Trainer(\n",
                "    model=model_full,\n",
                "    args=full_finetuning_args,\n",
                "    train_dataset=tokenized_train,\n",
                "    eval_dataset=tokenized_test,\n",
                "    tokenizer=tokenizer,\n",
                "    compute_metrics=compute_metrics,\n",
                ")\n",
                "\n",
                "# 학습 시작!\n",
                "print(\"Full Fine-Tuning 학습 시작...\")\n",
                "trainer_full.train()\n",
                "\n",
                "# 학습된 모델 저장\n",
                "trainer_full.save_model(\"./saved_models/full_finetune_final\")\n",
                "print(\"Full Fine-Tuning 학습 및 저장 완료!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. PEFT (LoRA) 모델 학습\n",
                "적은 파라미터만 학습하여 효율적인 PEFT(LoRA) 방식을 수행합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "베이스 모델을 다시 로드합니다 (PEFT용)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PEFT 적용 후 학습 파라미터 확인:\n",
                        "trainable params: 887,811 || all params: 111,508,230 || trainable%: 0.7962\n",
                        "PEFT (LoRA) 학습 시작...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_2741255/3667435231.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
                        "  trainer_peft = Trainer(\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='9227' max='9227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [9227/9227 34:04, Epoch 1/1]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "      <th>F1</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.250600</td>\n",
                            "      <td>0.229194</td>\n",
                            "      <td>0.909118</td>\n",
                            "      <td>0.876061</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PEFT 학습 및 저장 완료!\n"
                    ]
                }
            ],
            "source": [
                "# ==========================================\n",
                "# 3. PEFT (LoRA) 모델 학습\n",
                "# ==========================================\n",
                "\n",
                "# PEFT 라이브러리에서 필요한 모듈을 가져옵니다.\n",
                "from peft import LoraConfig, get_peft_model, TaskType\n",
                "\n",
                "# 1. 베이스 모델을 다시 새로 불러옵니다 (Full Fine-tuning된 모델이 아니라 깨끗한 상태로 시작하기 위해)\n",
                "# 메모리 부족 방지를 위해 기존 모델 삭제 및 캐시 정리\n",
                "import torch\n",
                "del model_full\n",
                "del trainer_full\n",
                "torch.cuda.empty_cache()\n",
                "\n",
                "print(\"베이스 모델을 다시 로드합니다 (PEFT용)...\")\n",
                "model_peft = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=3)\n",
                "\n",
                "# 2. LoRA 설정 정의\n",
                "# r: LoRA의 Rank (크면 클수록 학습할 파라미터가 늘어나지만 성능이 좋아질 수 있음, 보통 8, 16 사용)\n",
                "# lora_alpha: Scaling factor\n",
                "# target_modules: LoRA를 적용할 모듈 (RoBERTa의 경우 query, value에 주로 적용)\n",
                "peft_config = LoraConfig(\n",
                "    task_type=TaskType.SEQ_CLS, \n",
                "    inference_mode=False, \n",
                "    r=8, \n",
                "    lora_alpha=16, \n",
                "    lora_dropout=0.1,\n",
                "    target_modules=[\"query\", \"value\"] # roberta 구조에 맞게 설정\n",
                ")\n",
                "\n",
                "# 3. 모델에 LoRA 적용\n",
                "model_peft = get_peft_model(model_peft, peft_config)\n",
                "\n",
                "# 학습 가능한 파라미터 수 출력 (Full Fine-tuning 대비 얼마나 줄었는지 확인해보세요!)\n",
                "print(\"PEFT 적용 후 학습 파라미터 확인:\")\n",
                "model_peft.print_trainable_parameters()\n",
                "\n",
                "# 4. PEFT 학습 설정 (거의 동일하지만 저장 경로만 다르게)\n",
                "peft_training_args = TrainingArguments(\n",
                "    output_dir=\"./saved_models/peft_lora\",\n",
                "    eval_strategy=\"epoch\", # [수정] evaluation_strategy -> eval_strategy\n",
                "    save_strategy=\"epoch\",\n",
                "    learning_rate=1e-3, # LoRA는 보통 학습률을 조금 더 크게 잡습니다 (예: 1e-3 ~ 5e-4)\n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=16,\n",
                "    num_train_epochs=1, # 비교를 위해 동일하게 1 epoch\n",
                "    weight_decay=0.01,\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=\"accuracy\",\n",
                "    save_total_limit=1\n",
                ")\n",
                "\n",
                "# 5. Trainer 생성\n",
                "trainer_peft = Trainer(\n",
                "    model=model_peft,\n",
                "    args=peft_training_args,\n",
                "    train_dataset=tokenized_train,\n",
                "    eval_dataset=tokenized_test,\n",
                "    tokenizer=tokenizer,\n",
                "    compute_metrics=compute_metrics,\n",
                ")\n",
                "\n",
                "# 학습 시작!\n",
                "print(\"PEFT (LoRA) 학습 시작...\")\n",
                "trainer_peft.train()\n",
                "\n",
                "# 모델 저장\n",
                "trainer_peft.save_model(\"./saved_models/peft_lora_final\")\n",
                "print(\"PEFT 학습 및 저장 완료!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. 성능 비교 및 결론\n",
                "Full Fine-Tuning과 PEFT(LoRA)의 학습 결과(정확도, F1 Score)와 효율성을 비교하고 결론을 도출합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Full Fine-Tuning 모델 평가 중...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='2307' max='2307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [2307/2307 03:21]\n",
                            "    </div>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PEFT 모델 평가 결과: {'eval_loss': 0.22919422388076782, 'eval_accuracy': 0.9091180056902859, 'eval_f1': 0.8760609220990934, 'eval_runtime': 201.7116, 'eval_samples_per_second': 182.959, 'eval_steps_per_second': 11.437, 'epoch': 1.0}\n",
                        "\n",
                        "[결론]\n",
                        "PEFT(LoRA)는 적은 리소스로도 Full Fine-Tuning에 준하는 성능을 낼 수 있는 효율적인 방법입니다.\n",
                        "특히 대규모 언어 모델(LLM)을 다룰 때 이러한 효율성은 매우 중요합니다.\n"
                    ]
                }
            ],
            "source": [
                "# 두 모델의 최종 성능을 평가합니다.\n",
                "print(\"Full Fine-Tuning 모델 평가 중...\")\n",
                "# 주의: trainer_full 객체가 메모리에서 삭제되었다면 다시 로드해야 할 수 있습니다.\n",
                "# 여기서는 위에서 삭제했으므로, 저장된 모델을 다시 불러와서 평가하거나,\n",
                "# 로그(log_history)를 통해 확인하는 방법을 사용합니다.\n",
                "\n",
                "# 간단하게 PEFT 모델의 평가 결과만이라도 확인해봅니다.\n",
                "peft_eval_result = trainer_peft.evaluate()\n",
                "print(\"PEFT 모델 평가 결과:\", peft_eval_result)\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# [결과 비교 및 요약]\n",
                "# ---------------------------------------------------------\n",
                "# 실제 학습을 돌려보면 다음과 같은 경향을 보입니다:\n",
                "# 1. Full Fine-Tuning:\n",
                "#    - 모든 파라미터를 학습하므로 성능(Accuracy)이 가장 높을 가능성이 큽니다.\n",
                "#    - 하지만 학습 시간이 오래 걸리고, GPU 메모리를 많이 차지합니다.\n",
                "#    - 모델 파일 용량이 큽니다 (약 400MB+).\n",
                "#\n",
                "# 2. PEFT (LoRA):\n",
                "#    - 학습 파라미터 수가 매우 적습니다 (전체의 1% 미만).\n",
                "#    - 학습 속도가 빠르고 메모리 사용량이 적습니다.\n",
                "#    - 성능은 Full Fine-Tuning과 비슷하거나 약간 낮을 수 있지만, 효율성 면에서 압도적입니다.\n",
                "#    - 모델 파일 용량이 매우 작습니다 (몇 MB 수준).\n",
                "\n",
                "print(\"\\n[결론]\")\n",
                "print(\"PEFT(LoRA)는 적은 리소스로도 Full Fine-Tuning에 준하는 성능을 낼 수 있는 효율적인 방법입니다.\")\n",
                "print(\"특히 대규모 언어 모델(LLM)을 다룰 때 이러한 효율성은 매우 중요합니다.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. 추론 테스트 (Inference)\n",
                "학습된 PEFT 모델을 사용하여 실제 문장의 감성을 예측해봅니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[PEFT 모델 추론 결과]\n",
                        "문장: 배송이 너무 느려서 화가 나네요. -> 예측: 부정\n",
                        "문장: 디자인은 예쁜데 사이즈가 좀 작아요. -> 예측: 중립\n",
                        "문장: 정말 마음에 듭니다! 재구매 의사 있어요. -> 예측: 긍정\n"
                    ]
                }
            ],
            "source": [
                "# 학습된 모델로 새로운 문장 테스트해보기\n",
                "def predict_sentiment(text, model, tokenizer):\n",
                "    # 입력 문장 토큰화\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
                "    \n",
                "    # GPU로 이동\n",
                "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
                "    \n",
                "    # 예측\n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        logits = outputs.logits\n",
                "        prediction = torch.argmax(logits, dim=-1).item()\n",
                "        \n",
                "    # 라벨 매핑 (0: 부정, 1: 중립, 2: 긍정)\n",
                "    label_map_inv = {0: \"부정\", 1: \"중립\", 2: \"긍정\"}\n",
                "    return label_map_inv[prediction]\n",
                "\n",
                "# 테스트 문장\n",
                "test_sentences = [\n",
                "    \"배송이 너무 느려서 화가 나네요.\",\n",
                "    \"디자인은 예쁜데 사이즈가 좀 작아요.\",\n",
                "    \"정말 마음에 듭니다! 재구매 의사 있어요.\"\n",
                "]\n",
                "\n",
                "print(\"[PEFT 모델 추론 결과]\")\n",
                "for sent in test_sentences:\n",
                "    result = predict_sentiment(sent, model_peft, tokenizer)\n",
                "    print(f\"문장: {sent} -> 예측: {result}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "codeit_1",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
