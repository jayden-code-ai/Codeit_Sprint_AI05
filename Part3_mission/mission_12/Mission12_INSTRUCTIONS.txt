# 미션 12: Hugging Face Transformers를 활용한 문서 요약

---

## 1. 미션 소개

- 이 미션의 목표는 **Hugging Face Transformers** 라이브러리를 활용하여  
  AI-Hub 문서요약 데이터(뉴스/사설/법률)를 요약하는 **엔드 투 엔드 파이프라인**을 구축하는 것이다.
- 데이터 로드 → 전처리 → 사전학습 요약 모델 적용/미세조정(Fine-tuning) → 평가(ROUGE, 예시 확인)까지  
  하나의 노트북 안에서 흐름이 자연스럽게 이어지도록 정리한다.

---

## 2. 미션 목표

- **실용적인 한글 문서 요약 파이프라인 구현**
  - 대용량 JSON 데이터를 효율적으로 로드하고, 요약 태스크에 맞게 전처리한다.
  - Hugging Face의 사전학습 요약 모델(T5, BART, Pegasus 등)을 활용해 **베이스라인 성능**을 확보한다.
- **모델 성능 이해 및 개선 시도**
  - ROUGE 등의 정량 지표와 실제 예시 출력을 함께 보면서 모델의 장단점을 파악한다.
  - 입력 길이 조절, 전처리 방식, 프롬프트/하이퍼파라미터 조정 등을 통해 성능 개선 가능성을 탐색한다.
- **재사용 가능한 템플릿 확보**
  - 이후 다른 요약 데이터셋에도 재사용할 수 있는 **일반적인 문서 요약 노트북 구조**를 만든다.

---

## 3. 데이터 소개

- **데이터 출처**
  - AI-Hub 문서요약 텍스트 데이터
  - 문서 유형: **신문 기사, 사설, 법률** (각각 train / test 쌍으로 구성)
- **데이터 형식**
  - JSON 파일 형태
  - 주요 필드(예시):  
    - `article` 또는 `text`: 원문 문서 본문  
    - `summary`: 정답 요약문  
    - 그 외 메타데이터(문서 ID, 카테고리 등)
- **이 노트북에서의 활용 계획**
  - 우선 **한 가지 문서 유형(예: 뉴스 기사)**를 중심으로 파이프라인을 구축한 뒤,
    시간 및 자원 여유가 있을 경우 사설/법률로 확장하거나 비교한다.
  - 입력 텍스트 길이 분포를 확인해, 모델에 들어갈 수 있는 길이(max_length 등)를 설정한다.

---

## 4. 분석 및 구현 단계

### 4-1. 환경 설정 및 라이브러리 로드

- `transformers`, `datasets`(선택), `torch`, `pandas`, `numpy`, `tqdm` 등 필수 라이브러리 불러오기
- GPU 사용 가능 여부 확인 및 `device` 설정

### 4-2. 데이터 로드 및 기초 EDA

- JSON 파일에서 train/test 데이터를 로드한다.
- 샘플 몇 건을 출력하여 **원문(text)과 요약(summary)의 형식**을 확인한다.
- 문장/토큰 길이 분포(평균, p90, p95 등)를 간단히 확인하여
  - 너무 긴 문서의 비율
  - 모델 입력 길이 제한 필요성  
  을 파악한다.

### 4-3. 전처리 및 서브셋 구성

- 불필요한 공백, 특수문자, HTML 태그 등이 있다면 간단히 정제한다.
- Hugging Face 토크나이저가 처리 가능한 수준에서 **길이 제한 전략**을 정한다.
  - 예: `max_source_length`, `max_target_length` 설정
- 리소스를 고려해 **학습/평가에 사용할 서브셋 크기**를 설정한다.
  - 예: train N개, validation M개 샘플만 사용

### 4-4. 사전학습 요약 모델 선택 및 베이스라인 구성

- Hugging Face에서 사용할 요약 모델 선택
  - 예: `kogbart`, `KcT5`, `mt5`, `kobart-summarization` 등 한글 지원 모델
- 두 가지 접근 중 최소 하나를 수행:
  1. **단순 추론(Baseline inference)**  
     - `pipeline("summarization", model=..., tokenizer=...)` 형태로 바로 요약 수행  
     - fine-tuning 없이도 어느 정도 요약이 되는지 확인
  2. **꼭 필요한 경우, 간단한 Fine-tuning**  
     - `Seq2SeqTrainer` 또는 `Trainer`를 사용해 train 데이터 일부로  
       몇 epoch fine-tuning (리소스 상황에 따라 선택)

### 4-5. 학습(선택) 및 요약 생성

- Fine-tuning을 한다면:
  - `TrainingArguments` 설정 (batch size, lr, epoch 수, logging/eval interval 등)
  - train/validation 데이터셋으로 학습 진행
- 학습 유무와 관계없이:
  - 테스트 또는 검증 데이터에서 여러 샘플을 뽑아 **모델 요약 결과**를 생성한다.
  - 길이 조절 파라미터(`max_length`, `min_length`, `num_beams`, `no_repeat_ngram_size`)를 조정해서
    요약 스타일 변화를 관찰한다.

---

## 5. 모델 성능 평가

### 5-1. 정량 평가 (ROUGE)

- 참조 요약문과 모델 요약문을 비교하여 **ROUGE-1 / ROUGE-2 / ROUGE-L** 점수를 계산한다.
- 베이스라인 vs (선택) Fine-tuning 모델 간 ROUGE 점수를 비교한다.
  - 어떤 설정에서 성능이 개선되었는지 간단히 표/텍스트로 정리한다.

### 5-2. 정성 평가 (요약 결과 분석)

- 다양한 길이/유형의 문서를 뽑아서
  - 원문 일부
  - 정답 요약
  - 모델 요약  
  을 나란히 출력하고, 다음 관점에서 코멘트한다.
  - 핵심 내용이 잘 유지되는지
  - 불필요한 세부 정보가 얼마나 제거되는지
  - 문장 자연스러움, 반복 여부, 중요한 정보 누락 여부 등
- 필요하다면 **문서 유형별(기사/사설/법률)**로 예시를 나누어  
  어떤 도메인에서 더 잘/못 동작하는지 관찰한다.

### 5-3. 종합 정리

- 이번 미션에서 사용한
  - 모델 선택 이유
  - 전처리 전략
  - 하이퍼파라미터 선택 기준
- 얻은 결과(ROUGE, 예시)를 바탕으로
  - 현재 파이프라인의 한계
  - 개선 아이디어 (더 큰 모델, 더 긴 학습, 도메인별 모델, 길이/프롬프트 조정 등)  
  을 간단히 정리하고 마무리한다.

==============================위 내용은 notebook최상단 markdown형태로 삽입되어야 할 내용=================================

중요!!!= 모든 답변과 작성은 "한국어"로 진행해줘

1. 위 내용 모두 숙지해줘
2. conda에서 새로운 가상환경 만들어서 진행할거야 가상환경의 이름은 codeit_1
3. 가상환경의 파이썬 버전은 위 내용을 가동하기 알맞는 버전을 추천해줘
3-1. 필요한 패키지 설치 도와줘
4. 위 내용을 터미널에서 실행할 수 있도록 명령어 안내해줘
5. 위 모든 작업이 완료 되었는지 확인 후에 notebook 제작 진행해줘

미션12 파일 경로
노트북 생성경로
/mnt/nas/jayden_code/Codeit_Practice/Part3_mission_12
노트북 제목(생성해줘야함)
미션12_1팀 정수범_1st.ipynb

미션 데이터 경로
/mnt/nas/jayden_code/Codeit_Practice/Part3_mission_12/summarization

꼭 참고해야되는 baseline코드
/mnt/nas/jayden_code/Codeit_Practice/Part3_mission_12/[스프린트미션]12_문서요약.ipynb


코드 진행 요청
- EDA를 충분하게 진행해줘. 발표 자료에 첨부 할수 있는 형태로 그래프 시각화 등 각좋 보기 좋은 자료 제공해줘
- 필요에 따라 DataFrame을 진행해 자료를 분석해줘
- 이상치 결측치 등 데이터 전처리도 필요하면 시행해줘
- 결과분석시 표로 볼수 있도록 해줘
- 전반적인 부분들이 코드를 모르는 사람들도 알기 쉽도록 시각화 자료 및 다양한 방법 고민해봐줘
- 코드 작성시 코드의 작동원리나 동작방식에 대해서 주석으로 설명 달아서 제작 부탁해
- 1개의 셀에 너무 많은 코드가 진행되지 않도록 부탁해 필요에 따라 셀을 분리해서 진행될수 있도록 해줘
- 코드의 오류가 없도록 패키지 및 각종 사항들 사전에 먼저 체크하고 진행될 수 있도록 해줘
- 나에게 추가 요청 사항 및 질문사항이 있다면 코드 진행 사전에 미리 물어보고 답을 얻은 뒤 진행해줘~!!