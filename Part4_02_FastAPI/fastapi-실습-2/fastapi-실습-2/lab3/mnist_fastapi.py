"""
ğŸ¯ FastAPI ì‹¤ìŠµ: PyTorch MNIST CNN ëª¨ë¸ ì„œë¹™
1. ì§ì ‘ í•™ìŠµí•œ PyTorch ëª¨ë¸(.pth)ì„ ë¡œë“œí•˜ì—¬ APIë¡œ ì„œë¹™
2. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ê°€ í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•´ì•¼ í•˜ëŠ” ì´ìœ  ì´í•´
3. CNN ì…ë ¥ í˜•íƒœ ë³€í™˜ (1D ë¦¬ìŠ¤íŠ¸ â†’ 4D í…ì„œ) ì „ì²˜ë¦¬ íŒ¨í„´
4. Softmaxë¥¼ í™œìš©í•œ í™•ë¥  ê¸°ë°˜ ì˜ˆì¸¡ ë° confidence ë°˜í™˜

ğŸ“Œ ì‚¬ì „ ì¤€ë¹„:
1. pip install torch
2. í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ì¤€ë¹„: mnist_cnn.pth (ê°™ì€ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜)

ğŸ“Œ ì‹¤í–‰ ë°©ë²•:
python mnist_fastapi.py


ğŸ’¡ ì…ë ¥ ë°ì´í„° í˜•íƒœ ë³€í™˜ ê³¼ì •:
- ì…ë ¥: [784] - 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ (28Ã—28 í¼ì¹œ ê²ƒ)
- ë³€í™˜: [1, 1, 28, 28] - [ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„]
- CNNì€ ë°˜ë“œì‹œ 4ì°¨ì› í…ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ!

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ëª¨ë¸ í´ë˜ìŠ¤(MNISTModel)ëŠ” í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì½”ë“œì™€ 100% ë™ì¼í•´ì•¼ í•¨
- í”½ì…€ê°’ì€ 0.0~1.0 ì‚¬ì´ë¡œ ì •ê·œí™”ëœ ê°’ì´ì–´ì•¼ í•¨
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from contextlib import asynccontextmanager
import torch
import torch.nn as nn

# --- 1. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ìœ ì˜: í•™ìŠµí•œ ì½”ë“œì™€ ì™„ì „íˆ ë™ì¼í•´ì•¼ í•¨) ---
class MNISTModel(nn.Module):
    def __init__(self):
        super(MNISTModel, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32*13*13, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.flatten(x)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x
    
# --- 2. ì „ì—­ ë³€ìˆ˜ ---
ml_models = {}

# --- 3. Lifespan (ëª¨ë¸ ë¡œë“œ) ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("===== ì„œë²„ ì‹œì‘: MNIST ëª¨ë¸ ë¡œë”© ì¤‘ ...")
    try:
        model = MNISTModel()

        from pathlib import Path
        MODEL_PATH = Path(__file__).parent / "mnist_cnn.pth"
        model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
        model.eval()
        ml_models["mnist"] = model
        print("âœ… MNIST ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")

    except Exception as e:
        print(f"!!! ëª¨ë¸ ë¡œë“œ ì‹¤í”¼: {e}")
        ml_models["mnist"] = None

    yield
    ml_models.clear()

app = FastAPI(lifespan=lifespan)

# --- 4. ì…ë ¥ ìŠ¤í‚¤ë§ˆ ---
class ImageRequest(BaseModel):
    # 28x28 = 784ê°œì˜ í”½ì…€ ê°’ (0.0 ~ 1.0 ì‚¬ì´ì˜ í‘ë°± ê°•ë„)
    pixels: list[float] = Field(..., min_length=784, max_length=784)

# --- 5. ì¶”ë¡  API ---
@app.post("/predict/digit")
async def predict_digit(request: ImageRequest):
    model = ml_models.get("mnist")
    if not model:
        raise HTTPException(status_code=500, detail="Model not loaded")
    
    # [ì „ì²˜ë¦¬]
    # 1. ë¦¬ìŠ¤íŠ¸ -> í…ì„œ ë³€í™˜
    input_tensor = torch.tensor(request.pixels, dtype=torch.float32)

    # 2. í˜•íƒœ ë³€í™˜ (Reshape): [784] -> [ë°°ì¹˜í¬ê¸° 1, ì±„ë„ 1, ë†’ì´ 28, ë„ˆë¹„ 28]
    # CNN ëª¨ë¸ì€ 4ì°¨ì› ì…ë ¥ í•´ì•¼í•¨
    input_tensor = input_tensor.view(1,1,28,28)

    # [ì¶”ë¡ ]
    with torch.no_grad():
        logits = model(input_tensor)
        # Softmaxë¥¼ ê±°ì³ í™•ë¥ ë¡œ ë³€í™˜
        prob = torch.nn.functional.softmax(logits, dim=1)

    # [í›„ì²˜ë¦¬]
    # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ ìˆ«ìì˜ ì¸ë±ìŠ¤(.argmax())ì™€ ê·¸ í™•ë¥ ê°’(.max()) ê°€ì ¸ì˜¤ê¸°
    predicted_class = prob.argmax().item()
    confidence = prob.max().item()

    return {
        "prediction": predicted_class,              # ì˜ˆì¸¡ëœ ìˆ«ì(0-9)
        "confidence": f"{confidence*100:.2f}%"      # í™•ì‹ ë„
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)