import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(title="ë‚˜ë§Œì˜ LLM API ì„œë²„")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1ë‹¨ê³„ : ê¸°ë³¸ ì±„íŒ… ì™„ì„± API 
class Message(BaseModel):
    role: str = Field(pattern=r"^(user|assistant|system)$")
    content: str

class ChatRequest(BaseModel):
    messages: List[Message]
    model: str = "gpt-4o-mini"
    temperature: float = Field(default=0.7, ge=0, le=2)
    max_tokens: int = Field(default=1000, ge=1, le=4096)

    model_config = {
        "json_schema_extra":{
            "examples": [{
                "messages": [
                    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”!"}
                ]
            }]
        }
    }

class ChatResponse(BaseModel):
    response: str
    model: str
    usage: dict

@app.get("/")
def home():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {"message": "LLM API ì„œë²„ê°€ ì‹¤í–‰ì¤‘ì…ë‹ˆë‹¤..."}

@app.post("/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    """
    ê¸°ë³¸ ì±„íŒ… API

    ğŸ’¡ OpenAI APIë¥¼ ê·¸ëŒ€ë¡œ ë…¸ì¶œí•˜ì§€ ì•Šê³  ë˜í•‘í•˜ëŠ” ì¥ì :
    1. API í‚¤ ë³´í˜¸ (í´ë¼ì´ì–¸íŠ¸ì— í‚¤ ë…¸ì¶œ ì•ˆ í•¨)
    2. ìš”ì²­/ì‘ë‹µ í˜•ì‹ ì»¤ìŠ¤í„°ë§ˆì´ì§•
    3. ë¡œê¹…, ëª¨ë‹ˆí„°ë§ ì¶”ê°€ ê°€ëŠ¥
    4. ë¹„ìš© ì œì–´ (max_tokens ì œí•œ ë“±)
    """
    try:
        response = client.chat.completions.create(
            model=request.model,
            messages=[m.model_dump() for m in request.messages],
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        return ChatResponse(
            response=response.choices[0].message.content,
            model=response.model,
            usage={
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))