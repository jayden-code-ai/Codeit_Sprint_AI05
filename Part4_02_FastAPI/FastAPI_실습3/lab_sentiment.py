"""
ğŸ¯ FastAPI ì‹¤ìŠµ: HuggingFace ê°ì„± ë¶„ì„ ëª¨ë¸ ì„œë¹™
1. Lifespanì„ í™œìš©í•œ Transformers íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ë¡œë”©
2. sentiment-analysis íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í…ìŠ¤íŠ¸ ê°ì„± ë¶„ë¥˜
3. Pydantic BaseModelì„ ì‚¬ìš©í•œ ìš”ì²­ ë°ì´í„° ê²€ì¦
4. POSITIVE/NEGATIVE ë¶„ë¥˜ ë° í™•ì‹ ë„(score) ë°˜í™˜

ğŸ“Œ ì‚¬ì „ ì¤€ë¹„:
1. pip install fastapi uvicorn transformers torch pillow
2. ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ (distilbert-base-uncased-finetuned-sst-2-english)

ğŸ“Œ ì‹¤í–‰ ë°©ë²•:
python ./frontend/lab_sentiment.py

ğŸ’¡ ê°ì„± ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ:
- "I love this!" â†’ {"label": "POSITIVE", "score": 0.9998}
- "This is terrible" â†’ {"label": "NEGATIVE", "score": 0.9995}

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ê¸°ë³¸ ëª¨ë¸ì€ ì˜ì–´ í…ìŠ¤íŠ¸ì— ìµœì í™”ë˜ì–´ ìˆìŒ
- í•œêµ­ì–´ ê°ì„± ë¶„ì„ì€ ë³„ë„ í•œêµ­ì–´ ëª¨ë¸ í•„ìš” (ì˜ˆ: beomi/KcELECTRA)
"""

from fastapi import FastAPI
from pydantic import BaseModel
from contextlib import asynccontextmanager
from transformers import pipeline

# 1. ëª¨ë¸ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸
ml_models = {}

# 2. Lifespan
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
    # ê°ì„± ë¶„ì„(sentiment-analysis) íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    ml_models["sentiment_analyzer"] = pipeline("sentiment-analysis")
    print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    yield
    # ì•± ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ì½”ë“œ (ì—¬ê¸°ì„  ë¦¬ì†ŒìŠ¤ í•´ì œí•  ê²Œ ì—†ìœ¼ë¯€ë¡œ ë¹„ì›Œë‘ )
    ml_models.clear()

app = FastAPI(lifespan=lifespan)

# ë°ì´í„° ì…ë ¥ í˜•ì‹ì„ ì •ì˜
class TextRequest(BaseModel):
    text: str

@app.post("/analyze-sentiment")
def analyze_sentiment(request: TextRequest):
    # ë¡œë“œëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    analyzer = ml_models["sentiment_analyzer"]
    
    # ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
    result = analyzer(request.text)
    
    # ê²°ê³¼ ë°˜í™˜ (label: POSITIVE/NEGATIVE, score: í™•ì‹ ë„)
    return {"original_text": request.text, "result": result[0]}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)